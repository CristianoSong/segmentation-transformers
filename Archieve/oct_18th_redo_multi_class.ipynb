{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10-18\n",
    "- Redo the multiclass case\n",
    "- The result looks like a binary classification - only 2 classes\n",
    "- **Check loss function?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import random\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from pathlib import Path\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.utils.data as Data\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.nn import functional as F\n",
    "from torchvision import models, transforms\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib\n",
    "import tqdm\n",
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"C:/Users/Siyao/Downloads/EndoVis2017Data\")\n",
    "train_path = data_path / \"cropped_train\"\n",
    "\n",
    "def get_split(fold):\n",
    "    \"\"\"Split train and valid dataset based on the No. of folder\"\"\"\n",
    "    folds = {0: [1, 3],\n",
    "             1: [2, 5],\n",
    "             2: [4, 8],\n",
    "             3: [6, 7]}\n",
    "    train_path = data_path / 'cropped_train'\n",
    "\n",
    "    train_file_names = []\n",
    "    val_file_names = []\n",
    "\n",
    "    for instrument_id in range(1, 9):\n",
    "        if instrument_id in folds[fold]:\n",
    "            val_file_names += list((train_path / ('instrument_dataset_' + str(instrument_id)) / 'images').glob('*'))\n",
    "        else:\n",
    "            train_file_names += list((train_path / ('instrument_dataset_' + str(instrument_id)) / 'images').glob('*'))\n",
    "\n",
    "    return train_file_names, val_file_names\n",
    "\n",
    "train_file_names, val_file_names = get_split(0)\n",
    "\n",
    "def load_image(path):\n",
    "    img = cv2.imread(str(path))\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "binary_factor = 255\n",
    "parts_factor = 85\n",
    "instrument_factor = 32\n",
    "\n",
    "def load_mask(path, problem_type=\"binary\", mask_folder=\"instruments_masks\",factor=instrument_factor):\n",
    "    if problem_type == 'binary':\n",
    "        mask_folder = 'binary_masks'\n",
    "        factor = binary_factor\n",
    "    elif problem_type == 'parts':\n",
    "        mask_folder = 'parts_masks'\n",
    "        factor = parts_factor\n",
    "    elif problem_type == 'instruments':\n",
    "        factor = instrument_factor\n",
    "        mask_folder = 'instruments_masks'\n",
    "\n",
    "    mask = cv2.imread(str(path).replace('images', mask_folder).replace('jpg', 'png'), 0)\n",
    "\n",
    "    return (mask / factor).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = 5\n",
    "train_img_path = [str(i) for i in train_file_names]\n",
    "train_frame_name = [i for i in train_img_path if int(i[-7:-4])>=tau]\n",
    "valid_img_path = [str(i) for i in val_file_names] \n",
    "valid_frame_name = [i for i in valid_img_path if int(i[-7:-4])>=tau]\n",
    "\n",
    "class InstrumentDataset(Dataset):\n",
    "    \"\"\"Dataset that loads multiple frame\"\"\"\n",
    "\n",
    "    def __init__(self, file_names, problem_type=\"binary\", tau=5):\n",
    "        self.file_names = file_names\n",
    "        self.problem_type = problem_type\n",
    "        self.tau = tau      # tau is the number of frames should be combiend\n",
    "        self.transform = transforms.Compose([\n",
    "                                transforms.ToPILImage(),\n",
    "                                transforms.Resize([256,320]),\n",
    "                                transforms.ToTensor()\n",
    "                            ]) \n",
    "    def __len__(self):\n",
    "        return len(self.file_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        current_frame = self.file_names[idx]\n",
    "        # mask = load_mask(current_frame, self.problem_type)\n",
    "        # mask = self.transform(mask)\n",
    "        frames_ls = []\n",
    "        masks_ls = []\n",
    "        for i in range(tau):\n",
    "            to_find = \"frame\"+current_frame[-7:-4]\n",
    "            to_repl = \"frame\"+ '%03d' % (int(current_frame[-7:-4])-i)\n",
    "            frame = current_frame.replace(to_find, to_repl)\n",
    "            frame_array = load_image(frame)\n",
    "            frame_tensor = self.transform(frame_array)\n",
    "            mask_array = load_mask(frame,problem_type=self.problem_type)\n",
    "            mask_tensor = torch.from_numpy(mask_array)\n",
    "            # mask_tensor = self.transform(mask_array)\n",
    "            # Change the value in mask to 1 - 0 \n",
    "            # mask_tensor = torch.where(mask_tensor>0,1,0)           \n",
    "            frames_ls.append(frame_tensor)\n",
    "            masks_ls.append(mask_tensor)\n",
    "        frames_stack = torch.stack(frames_ls, 0)\n",
    "        masks_stack = torch.stack(masks_ls, 0)\n",
    "        # permute the tensor from [tau, H, W, C] to [tau, C, H, W]\n",
    "        # frames_tensor = frames_stack.permute(0,3,1,2) \n",
    "        return frames_stack.float(), masks_stack.long(), str(current_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_frames = InstrumentDataset(train_frame_name,problem_type=\"instruments\",tau=tau)\n",
    "valid_data_frames = InstrumentDataset(valid_frame_name,problem_type=\"instruments\",tau=tau)\n",
    "\n",
    "batch_size = 1\n",
    "training_data_loader = Data.DataLoader(training_data_frames, batch_size=batch_size, shuffle=True)\n",
    "valid_data_loader = Data.DataLoader(valid_data_frames, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: torch.Size([1, 5, 3, 256, 320])\n",
      "Mask shape: torch.Size([1, 5, 1024, 1280])\n",
      "Path: ('C:\\\\Users\\\\Siyao\\\\Downloads\\\\EndoVis2017Data\\\\cropped_train\\\\instrument_dataset_5\\\\images\\\\frame053.jpg',)\n"
     ]
    }
   ],
   "source": [
    "a,b,c = next(iter(training_data_loader))\n",
    "print(f\"Data shape: {a.shape}\")\n",
    "print(f\"Mask shape: {b.shape}\")\n",
    "print(f\"Path: {c}\")\n",
    "# img = a[0][0].permute(1,2,0)\n",
    "# plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNBackbone(nn.Module):\n",
    "    def __init__(self, model=\"resnet101\", pretrained=True):\n",
    "        super(CNNBackbone, self).__init__()\n",
    "        self.model_name = model\n",
    "        self.pretrained = pretrained\n",
    "        if self.model_name == \"resnet101\" and pretrained:\n",
    "            model = models.resnet101(pretrained=True)\n",
    "            self.cnn = torch.nn.Sequential(*(list(model.children())[:-4])).eval()\n",
    "        else:\n",
    "            raise NotImplementedError(\"Please use some pretrained CNN models\")\n",
    "        for param in self.cnn.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = self.cnn(x[0])\n",
    "        out = y.unsqueeze(0)\n",
    "        # out.shape = [batch_size, T, C, H, W] = [1, T, 1024, 16, 20]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding3D(nn.Module):\n",
    "    \"\"\"https://github.com/tatp22/multidim-positional-encoding/blob/master/positional_encodings/positional_encodings.py\"\"\"\n",
    "    \n",
    "    def __init__(self, channels=1024):\n",
    "        super(PositionalEncoding3D, self).__init__()\n",
    "        channels = int(np.ceil(channels/6)*2)\n",
    "        if channels % 2:\n",
    "            channels += 1\n",
    "        self.channels = channels\n",
    "        inv_freq = 1. / (10000 ** (torch.arange(0, channels, 2).float() / channels))\n",
    "        self.register_buffer('inv_freq', inv_freq)\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        # Input tensor shape: [batch_size, T, C, H, W] \n",
    "        \"\"\"\n",
    "        :param tensor: A 5d tensor of size (batch_size, x, y, z, ch)\n",
    "        :return: Positional Encoding Matrix of size (batch_size, x, y, z, ch)\n",
    "        \"\"\"\n",
    "        tensor = tensor.permute(0, 4, 3, 1, 2)\n",
    "        if len(tensor.shape) != 5:\n",
    "            raise RuntimeError(\"The input tensor has to be 5d!\")\n",
    "\n",
    "        batch_size, x, y, z, orig_ch = tensor.shape\n",
    "        pos_x = torch.arange(x, device=tensor.device).type(self.inv_freq.type())\n",
    "        pos_y = torch.arange(y, device=tensor.device).type(self.inv_freq.type())\n",
    "        pos_z = torch.arange(z, device=tensor.device).type(self.inv_freq.type())\n",
    "        sin_inp_x = torch.einsum(\"i,j->ij\", pos_x, self.inv_freq)\n",
    "        sin_inp_y = torch.einsum(\"i,j->ij\", pos_y, self.inv_freq)\n",
    "        sin_inp_z = torch.einsum(\"i,j->ij\", pos_z, self.inv_freq)\n",
    "        emb_x = torch.cat((sin_inp_x.sin(), sin_inp_x.cos()), dim=-1).unsqueeze(1).unsqueeze(1)\n",
    "        emb_y = torch.cat((sin_inp_y.sin(), sin_inp_y.cos()), dim=-1).unsqueeze(1)\n",
    "        emb_z = torch.cat((sin_inp_z.sin(), sin_inp_z.cos()), dim=-1)\n",
    "        emb = torch.zeros((x,y,z,self.channels*3),device=tensor.device).type(tensor.type())\n",
    "        emb[:,:,:,:self.channels] = emb_x\n",
    "        emb[:,:,:,self.channels:2*self.channels] = emb_y\n",
    "        emb[:,:,:,2*self.channels:] = emb_z\n",
    "        out = emb[None,:,:,:,:orig_ch].repeat(batch_size, 1, 1, 1, 1)\n",
    "        out = out.permute(0, 3, 4, 2, 1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseAttention(nn.Module):\n",
    "    \"\"\"Sparse Self Attention Module\"\"\"\n",
    "    def __init__(self, in_dim=1024):\n",
    "        \"\"\"The only iuput attribute is dimension\"\"\"\n",
    "        super(SparseAttention, self).__init__()\n",
    "        self.query_conv = nn.Conv3d(in_channels=in_dim, out_channels=in_dim//8, kernel_size=1)\n",
    "        self.key_conv = nn.Conv3d(in_channels=in_dim, out_channels=in_dim//8, kernel_size=1)\n",
    "        self.value_conv = nn.Conv3d(in_channels=in_dim, out_channels=in_dim, kernel_size=1)\n",
    "        self.softmax = nn.Softmax(dim=4)\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "        self.affinity = torch.zeros(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input tensor shape: [batch_size, T, channel, H, W] \n",
    "        # Permute x to : [batch_size, channel, H, W, T]\n",
    "        x = x.permute(0, 2, 3, 4, 1)\n",
    "        b, C, H, W, T = x.shape\n",
    "        proj_query = self.query_conv(x)\n",
    "        proj_query_H = proj_query.permute(0,3,4,1,2).contiguous().view(b*W*T,-1,H).permute(0,2,1) # [b*W*T,H,C]\n",
    "        proj_query_W = proj_query.permute(0,2,4,1,3).contiguous().view(b*H*T,-1,W).permute(0,2,1) # [b*H*T,W,C]\n",
    "        proj_query_T = proj_query.permute(0,2,3,1,4).contiguous().view(b*W*H,-1,T).permute(0,2,1) # [b*W*H,T,C]\n",
    "\n",
    "        proj_key = self.key_conv(x)\n",
    "        proj_key_H = proj_key.permute(0,3,4,1,2).contiguous().view(b*W*T,-1,H)      # [b*W*T,C,H]\n",
    "        proj_key_W = proj_key.permute(0,2,4,1,3).contiguous().view(b*H*T,-1,W)      # [b*H*T,C,W]\n",
    "        proj_key_T = proj_key.permute(0,2,3,1,4).contiguous().view(b*W*H,-1,T)      # [b*W*H,C,T]\n",
    "\n",
    "        proj_value = self.value_conv(x)\n",
    "        proj_value_H = proj_value.permute(0,3,4,1,2).contiguous().view(b*W*T,-1,H)      # [b*W*T,C,H]\n",
    "        proj_value_W = proj_value.permute(0,2,4,1,3).contiguous().view(b*H*T,-1,W)      # [b*H*T,C,W]\n",
    "        proj_value_T = proj_value.permute(0,2,3,1,4).contiguous().view(b*W*H,-1,T)      # [b*W*H,C,T]\n",
    "\n",
    "        energy_H = torch.bmm(proj_query_H, proj_key_H).view(b,W,T,H,H).permute(0,3,1,2,4) # [b,H,W,T,H]\n",
    "        energy_W = torch.bmm(proj_query_W, proj_key_W).view(b,H,T,W,W).permute(0,1,3,2,4) # [b,H,W,T,W]\n",
    "        energy_T = torch.bmm(proj_query_T, proj_key_T).view(b,H,W,T,T)                    # [b,H,W,T,T]\n",
    "        score = self.softmax(torch.cat([energy_H,energy_W,energy_T],4))         # [b,H,W,T,(H+W+T)]\n",
    "        affinity = torch.max(score, 4).values\n",
    "        self.affinity = affinity.permute(0,3,1,2)\n",
    "        \n",
    "        att_H = score[:,:,:,:,0:H].permute(0,2,3,1,4).contiguous().view(b*W*T,H,H)      # [b*W*T,H,H]\n",
    "        att_W = score[:,:,:,:,H:H+W].permute(0,1,4,2,3).contiguous().view(b*H*T,W,W)    # [b*H*T,W,W]\n",
    "        att_T = score[:,:,:,:,H+W:].contiguous().view(b*H*W,T,T)                        # [b*H*W,T,T]\n",
    "\n",
    "        out_H = torch.bmm(proj_value_H, att_H.permute(0,2,1)).view(b,W,T,-1,H).permute(0,3,4,1,2)\n",
    "        out_W = torch.bmm(proj_value_W, att_W.permute(0,2,1)).view(b,H,T,-1,W).permute(0,3,1,4,2)\n",
    "        out_T = torch.bmm(proj_value_T, att_T.permute(0,2,1)).view(b,H,W,-1,T).permute(0,3,1,2,4)\n",
    "        \n",
    "        # permute back to [batch_size, T, channel, H, W] \n",
    "        output = self.gamma*(out_H + out_T + out_W).permute(0,4,1,2,3)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 5, 1024, 16, 20]), torch.Size([1, 5, 1024, 16, 20]))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SA = SparseAttention()\n",
    "output = SA(z)\n",
    "output.shape, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSTEncoder(nn.Module):\n",
    "    \"\"\"Define the Multi-head attention -> Add&Norm -> Feed Forward -> Add&Norm module\"\"\"\n",
    "    def __init__(self, dim=512, dropout=0.2):\n",
    "        super(SSTEncoder, self).__init__()\n",
    "\n",
    "        # Multi-head attention sub-layer\n",
    "        self.attn = SparseAttention(dim)\n",
    "        self.norm_1 = nn.LayerNorm(dim)\n",
    "        \n",
    "        # Feed forward sub-layer\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_features=dim, out_features=dim*2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(in_features=dim*2, out_features=dim)\n",
    "        )\n",
    "        self.norm_2 =  nn.LayerNorm(dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y1 = self.attn(x)\n",
    "        x2 = (x+y1).permute(0,3,4,1,2)   # permute from [b,T,C,H,W] to [b,H,W,T,C]\n",
    "        y2 = self.norm_1(x2)\n",
    "        y3 = self.fc(y2)\n",
    "        out = self.norm_2(y2+y3).permute(0,3,4,1,2)  # permute from [b,H,W,T,C] to [b,T,C,H,W]\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    \"\"\"Define Decoder block for deconvolution\"\"\"\n",
    "    def __init__(self, in_channels, mid_channels, out_channels, deconv=True):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        # self.in_channels = in_channels\n",
    "        if deconv:\n",
    "            self.Deblock = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm2d(mid_channels),\n",
    "                nn.ReLU(),\n",
    "                nn.ConvTranspose2d(mid_channels, out_channels, kernel_size=4, stride=2, padding=1),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                \n",
    "            )\n",
    "        else:\n",
    "            self.Deblock = nn.Sequential(\n",
    "                nn.Upsample(scale_factor=2, mode='bilinar'),\n",
    "                nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.squeeze(0)\n",
    "        y = self.Deblock(x)\n",
    "        y = y.unsqueeze(0)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTransformer(nn.Module):\n",
    "    def __init__(self, num_layers=4):\n",
    "        super(MyTransformer, self).__init__()\n",
    "\n",
    "        self.backbone = CNNBackbone()\n",
    "        self.pos_encoding = PositionalEncoding3D()\n",
    "        self.self_attn1 = SSTEncoder()\n",
    "        self.self_attn2 = SSTEncoder()\n",
    "        self.self_attn3 = SSTEncoder()\n",
    "        self.self_attn4 = SSTEncoder()\n",
    "        self.self_attn5 = SSTEncoder()\n",
    "        self.dec1 = DecoderBlock(512*2+5,1024,512)\n",
    "        self.dec2 = DecoderBlock(512,512,256)\n",
    "        self.dec3 = DecoderBlock(256,256,8)\n",
    "        # self.dec4 = DecoderBlock(128,64,8)\n",
    "        self.cnn_feat = torch.zeros(1)\n",
    "        self.encod_feat = torch.zeros(1)\n",
    "        self.obj_aff = torch.zeros(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 1. subtract feature embedding from CNN backbone [b,T,C,H',W']\n",
    "        cnn_fs = self.backbone(x)\n",
    "        self.cnn_feat = cnn_fs\n",
    "        # Get positional encoding and add it to the feature embedding\n",
    "        pe = self.pos_encoding(cnn_fs)\n",
    "        y = pe + cnn_fs\n",
    "\n",
    "        # 2. Encoded feature from transformer layers \n",
    "        y = self.self_attn1(y)\n",
    "        y = self.self_attn2(y)\n",
    "        y = self.self_attn3(y)\n",
    "        y = self.self_attn4(y)\n",
    "        T_L = self.self_attn5(y)\n",
    "        self.encod_feat = T_L\n",
    "        \n",
    "        # 3. Object Affinity Value [N_layers,T,H',W']:\n",
    "        obj_aff = torch.cat([self.self_attn1.attn.affinity,\n",
    "                                          self.self_attn2.attn.affinity,\n",
    "                                          self.self_attn3.attn.affinity,\n",
    "                                          self.self_attn4.attn.affinity,\n",
    "                                          self.self_attn5.attn.affinity], 0)\n",
    "\n",
    "        # Adjust to [b,T,C,H',W']\n",
    "        obj_aff = obj_aff.transpose(0,1).unsqueeze(0)\n",
    "        self.obj_aff = obj_aff\n",
    "\n",
    "        # Concatnate feature together\n",
    "        emb = torch.cat([cnn_fs, T_L, obj_aff],dim=2)\n",
    "        # print(y.shape,T_L.shape,obj_aff.shape)\n",
    "        \n",
    "        z = self.dec1(emb)\n",
    "        z = self.dec2(z)\n",
    "        z = self.dec3(z)\n",
    "        # z = self.dec4(z)\n",
    "        output = F.interpolate(z[-1],scale_factor=4,mode='bilinear',align_corners=True)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 8, 1024, 1280]), torch.Size([1, 5, 1024, 1280]))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyTransformer()\n",
    "model = model.to(device)\n",
    "z = model(a.to(device))\n",
    "z.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2578, device='cuda:0', grad_fn=<NllLoss2DBackward>)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "loss = criterion(z.cuda(), b[0].cuda())\n",
    "loss.backward()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7], device='cuda:0')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = nn.Softmax(1)\n",
    "preds = softmax(z).argmax(1)\n",
    "preds[-1].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 1024, 1280]), torch.Size([8, 1024, 1280]))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b0 = b[0][-1]\n",
    "bone = F.one_hot(b0,num_classes=8).permute(2,0,1).cuda()\n",
    "z0 = z[-1].cuda()\n",
    "bone.shape, z0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jaccard(y_true, y_pred):\n",
    "    \"\"\"y_true, y_pred should be in the same shape [C,H,W]\"\"\"\n",
    "    epsilon = 1e-15\n",
    "    C = y_true.shape[-3]\n",
    "    jaccard_per_C = []\n",
    "    for i in range(C):\n",
    "        true = y_true[i].flatten()\n",
    "        pred = y_pred[i].flatten()\n",
    "        intersection = torch.sum(true * pred)\n",
    "        union = torch.sum(true) + torch.sum(pred)\n",
    "        jaccard = ((intersection + epsilon) / (union - intersection + epsilon)).data.cpu().numpy()\n",
    "        jaccard_per_C.append(jaccard)\n",
    "    return np.average(jaccard_per_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data, mask, _ = next(iter(training_data_loader))\n",
    "# data, mask = data.to(device), mask.to(device)\n",
    "# softmax = nn.Softmax(dim=1)\n",
    "# output = model(data)                            # Forward Passing\n",
    "# loss = criterion(output, mask[0])                  # Compute loss\n",
    "# preds = softmax(output).argmax(1)              # Make prediction\n",
    "# mask0 = F.one_hot(mask[0][-1], num_classes=8).permute(2,0,1)\n",
    "# pred0 = F.one_hot(preds[-1], num_classes=8).permute(2,0,1)\n",
    "# get_jaccard(mask0, pred0), loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataloader, valid_dataloader, criterion, optimizer, epochs):\n",
    "    # Initialize lists to store loss and fscore each epoch\n",
    "    LOSS_train = []\n",
    "    LOSS_valid = []\n",
    "    Jaccard_train = []\n",
    "    Jaccard_valid = []  \n",
    "    softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    for epoch in tqdm.trange(epochs, desc=\"Epochs\"):\n",
    "        result = []\n",
    "        train_loss = 0.0\n",
    "        train_Jaccard = 0.0\n",
    "        valid_loss = 0.0\n",
    "        valid_Jaccard = 0.0\n",
    "        # Begin training\n",
    "        model.train()\n",
    "        for data, mask, _ in train_dataloader:\n",
    "            data, mask = data.to(device), mask.to(device)\n",
    "\n",
    "            output = model(data)                            # Forward Passing\n",
    "            loss = criterion(output, mask[0])                  # Compute loss\n",
    "            preds = softmax(output).argmax(1)              # Make prediction\n",
    "            loss.backward()                                 # Compute gradients\n",
    "            optimizer.step()                                # Update the model parameters\n",
    "            optimizer.zero_grad()                           # Clear the gradients\n",
    "            mask0 = F.one_hot(mask[0][-1], num_classes=8).permute(2,0,1)\n",
    "            pred0 = F.one_hot(preds[-1], num_classes=8).permute(2,0,1)\n",
    "            train_loss += loss.item() * data.size(0)        # Compute training loss\n",
    "            train_Jaccard += get_jaccard(mask0, pred0)\n",
    "\n",
    "        # Begin validation\n",
    "        model.eval()\n",
    "        for data, mask, _ in valid_dataloader:\n",
    "            data, mask = data.to(device), mask.to(device)\n",
    "\n",
    "            output = model(data)                            # Forward Passing      \n",
    "            loss = criterion(output, mask[0])                  # Compute loss\n",
    "            preds = softmax(output).argmax(1)             # Make prediction\n",
    "            mask0 = F.one_hot(mask[0][-1], num_classes=8).permute(2,0,1)\n",
    "            pred0 = F.one_hot(preds[-1], num_classes=8).permute(2,0,1)\n",
    "            valid_loss += loss.item() * data.size(0)        # Compute validation loss\n",
    "            valid_Jaccard += get_jaccard(mask0, pred0)\n",
    "        \n",
    "        # Compute epoch loss and f1\n",
    "        epoch_train_loss = train_loss / len(train_dataloader.dataset)\n",
    "        epoch_train_Jaccard = train_Jaccard / len(train_dataloader.dataset)\n",
    "        epoch_valid_loss = valid_loss / len(valid_dataloader.dataset)\n",
    "        epoch_valid_Jaccard = valid_Jaccard / len(valid_dataloader.dataset)\n",
    "\n",
    "        # Record epoch loss and f1 to the list\n",
    "        LOSS_train.append(epoch_train_loss)\n",
    "        LOSS_valid.append(epoch_valid_loss)\n",
    "        Jaccard_train.append(epoch_train_Jaccard)\n",
    "        Jaccard_valid.append(epoch_valid_Jaccard)       \n",
    "\n",
    "        result.append(f'{epoch} TRAIN loss: {epoch_train_loss:.4f}, Jaccard: {epoch_train_Jaccard:.4f}   VALID loss: {epoch_valid_loss:.4f}, Jaccard: {epoch_valid_Jaccard:.4f}')\n",
    "        # result.append(f'{epoch} TRAIN loss: {epoch_train_loss:.4f}, VALID loss: {epoch_valid_loss:.4f}, ')\n",
    "\n",
    "        print(result)\n",
    "    return LOSS_train, LOSS_valid, Jaccard_train, Jaccard_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/2 [00:29<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-116-91a85ad56dab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mLOSS_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLOSS_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFSCORE_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFSCORE_valid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_data_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_data_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-115-9ee0bf4680e8>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, train_dataloader, valid_dataloader, criterion, optimizer, epochs)\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m                                \u001b[1;31m# Update the model parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m                           \u001b[1;31m# Clear the gradients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m             \u001b[0mmask0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m             \u001b[0mpred0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m        \u001b[1;31m# Compute training loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# criterion = LossMulti(0.5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "LOSS_train, LOSS_valid, FSCORE_train, FSCORE_valid = train(model, training_data_loader, valid_data_loader, criterion, optimizer, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: torch.Size([1, 5, 3, 256, 320])\n",
      "Mask shape: torch.Size([1, 5, 1024, 1280])\n",
      "Path: C:\\Users\\Siyao\\Downloads\\EndoVis2017Data\\cropped_train\\instrument_dataset_4\\images\\frame185.jpg\n"
     ]
    }
   ],
   "source": [
    "frame,mask,c = training_data_frames[400]\n",
    "# img = a[0][0].permute(1,2,0)\n",
    "# plt.imshow(img)\n",
    "frame = frame.unsqueeze(0)\n",
    "mask = mask.unsqueeze(0)\n",
    "print(f\"Data shape: {frame.shape}\")\n",
    "print(f\"Mask shape: {mask.shape}\")\n",
    "print(f\"Path: {c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(frame.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(img):\n",
    "    model.eval()\n",
    "    img = img.to(device)\n",
    "    pred = model(img)\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    pred = softmax(pred).argmax(1)\n",
    "    return pred[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 1280])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prd = prediction(frame)\n",
    "prd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x250607915e0>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT4AAAD8CAYAAADub8g7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAx9UlEQVR4nO3deXxU5d338c9vlsxkX0mAhCXsi7gCgrhjFRWXWrXYVrHF0lqt2u1Wa++n7f34dLP1Rmuta+uGIrUqat1RqlUWEQSBsEMgEJKQfZ3MnHM9f8yAQbKQdWYyv/frxWtmzpwz55eQfHOdc53rOmKMQSmlYokj3AUopVRf0+BTSsUcDT6lVMzR4FNKxRwNPqVUzNHgU0rFnD4PPhGZJSJbRGS7iNzR1/tXSinpy+v4RMQJbAW+AhQBnwDXGGM29VkRSqmY19ctvqnAdmPMTmNMM7AIuKyPa1BKxThXH+8vF9jb4nURcOqXVxKR+cB8ACfOUxJI6ZvqlFL9RgO1WATeMsbM+vJ7fR180sqyo461jTGPAI8ApEiGOW3c9zBuF466BuyycgDshgbQ4XZKqTasNEupMRVHhR70ffAVAUNavM4D9re3gbhcXPzSSi5KLGCvlcS6xmH4jZO/b5tG6sJkUt4uwKqp6dWilVL9S193brgIdm7MBPYR7Nz4hjFmY1vbpMZlmycLBnFpYsNR79XZTfymbCovLTmd/MUHsTbvANvqrfKVUlEk1OJr7Sizbzs3jDEB4GbgLaAAWNxe6HUkyeHlNznrKZj/IP/nteco+sc46r92Ks4UPSeolGpbXx/qYox5HXi9pz93mtfJxukLqT61kd+UTeeVJaeR/49yrILt2gpUSh2hTw91u6K9Q932WMZmhQ/mr72W9GeTSHlHzwUqFUvaO9Tt8xZfX3GKgxle2Dh9IZVTG/jdwdOCrcDFB7EKtmmPsFIxrN+2+FpjGZtPfIZ5a68jY2ESSe9swq6t7YEqlVKRJiZbfK1xioNpoVbgoXOBr754GsMXl2Jt26XnApWKETHV4mvLR002N3w6l6xnE0hequcCleoPIuZylkg1w+ugYMbTvPbnBYx/v469/30azrGjwl2WUqqXaIuvDW83uPn+R9cy7FkH3n9vwG5q6tP9K6W6R1t8XXB+gp+dX/kbzz92H4OXuSj+yWm4hg8FafX7qJSKIhp8Hch2JvL40P+w9scP8IN332bb30/Gf/5kHAkJ4S5NKdVFGnzHyCkOLk5oYuf5j7Po8fvIfDeOAz/SVqBS0UiDrwuynYk8M3wZa376AN975122/k1bgUpFEw2+bnCKg0sTG9h1weMsfGzBka1ApVTE0uDrIYNcSTwzfBmrf/pnvvvOe2z922T8552Cw+sNd2lKqS/R4OthbnFyeWIdu2Y9xsK/3Ufme95gK3DYkI43Vkr1CQ2+XtSyFfi9d5ey9fHJBM7VVqBS4abB1wfc4gyeC7zwMZ578n7Sl8ZT+oPTcA0aGO7SlIpJGnx9LNuZyLP577Pirvu44r3P2PbAqZjTTkDcceEuTamYocEXJh5xMy/1ADuveJi/PvcXzJvZlN8wHWdOdrhLU6rfi/zgi+yhxD1ipDuJt8a/xke/vp+vLVvPtvtPhWnHaytQqV4S+cFn27xXMyHcVfSJw63AKx/moecfxHozh/IbpuMamBPu0pTqVyI++Ixts6c+Pdxl9Ll8dxLvjH+Vj359P5e9/znb7puGma7nApXqCREffLHOI27mp+5n51UP8cCiB/G/MVBbgUp1kwZfFBnjTmTphFf46Nf3c8l7G75oBbpi6g4CSnWbBl8U8oib76ft+6IV+OZgyudpj7BSx0qDL8odbgX+z/1cvmwD2xdMg6mTtBWoVDs0+PqJQ+cCd1z9EA/+46+UvjiSyrnTcQ4YEO7SlIo4Gnz90Eh3EmsmP8+Hv7mfi/+9me33TsNx/Lhwl6VUxNDg68c84uamtL3smPMQAx7ejzMlJdwlKRURNPhixIND3qbqwti4EFypjmjwxYgkhxd77kG9AFopNPhiyuMTnsacNDbcZSgVdhp8MWRiXDzbv5EY7jKUCjsNvhhjp/rDXYJSYafBF2McLhtX/rBwl6FUWHU5+ERkiIi8LyIFIrJRRG4NLc8QkXdEZFvoMb3FNneKyHYR2SIiF/TEF6A6Z0BmLdOXbGHf7afhTEsNdzlKhUV3WnwB4CfGmPHANOAmEZkA3AEsNcaMBpaGXhN6bw4wEZgFPCgizu4UrzpvRs5OfpixllU/XEDavxwEZp4CDv1vULGly8FnjCk2xqwJPa8FCoBc4DLgydBqTwKXh55fBiwyxviMMbuA7cDUru5fdcwyNkWBOhbWZnL5tgsYvex63isaQ4LEkeCI49n893ng8T+z7c+TceUODne5SvWZHhnJLiLDgZOAlUCOMaYYguEoIoemDMkFVrTYrCi0rLXPmw/MB/CS0BMlxpxTPr0a+40s4uoMtUOF7DP3c8+UF7gwoRK3uA+vNz4ugW2X/5U/njmWF/9wHumLPsX4m8NYuVK9r9vBJyJJwD+B24wxNSLS5qqtLGv1jhrGmEeARwBSJCMG7rrRs4oDdVhvZ3H8tRv4xeA3GOmKxymHGvfuo9Z3ioPbM7fx7d98xswrvsuQn/uxCrb1bdFK9aFu9eqKiJtg6C00xrwYWlwiIoNC7w8CSkPLi4AhLTbPA/Z3Z/+qdb/YP4vakTZPDfuAMe7EFqHXvmxnIp+f+izjn9mhh76qX+tOr64AjwMFxph7W7z1CjA39HwusKTF8jki4hGRfGA0sKqr+1dt+3DZJL5+1sdd3v4PA1ez6a487fRQ/VZ3DnVnANcCn4vIZ6FlPwd+BywWkXnAHuAqAGPMRhFZDGwi2CN8kzHG6sb+VSvWNzfhOSj8LGsFdPH8qFMcvHfxvVz37k9IeHFlzxYYIu44nNlZ1J+QS/F0F06fkP/YDgIHSnplf0q1JMZE9im0FMkw6Y/cwZVTVnNJ2lomuRtIcXiP+fAt1sxYfwVlVUlsPfOpbn/W7SUnsmH2YAL7un9GwuH1IiOHUXl8OiXT4LQpm7kmewWneytJdcRjGZv/OTiJ5d+fjCxf1+39KbXSLKXGVLTa6RAV85OPuXENG+I8bMq6GN+oHCrHeqgeBcljKrl42EYuTFnHWHcj6Y74mA7E4kAdVR8M5O7rF/bI5/0mew2j7prKmJtLwO5E41wEZ0Y69ohcDkxPpnZqI5ePX8d3Mp9gjDsO9xGXb8YDwVbm/8n6nOljzyR9eY+Ur1SboiL4sC3sJgu7aB/Oon1kLYMsABE+9SSyNucyfPkDqBrpoXospE0o56IhGzknqYDj4mrJcvbvgfmlVj3XbbuaXR8NZejMvXwtsZKeGI146JB37ls/Jn5JO6djHU5cgwdSd2IuZSe4SJx+kJtGLePchFfIdSa0+GMU3+2alOoJ0RF8bTEGu6kJu3AvzsK9ZC6DzNBbqxJSWZ09m+a8DKpGx1M9Bpyj6jhz2Ha+mrGGkz0VpDu8X2p9RJ+DVj2nL/wpqceV8+Z195DvTqInh2Dnu5MY+/ON7F8/jMCuwqPer//aqWTcUsgPct/ldG81SQ5vi3eTOr0/sbtRrFLHKCrO8Z0qM3vs88TjwZmehj9/IFVjEqgeDY6xdVwwooCLUtcxKa6SLGd81ATivxq83F94Hm+Nf61X93PljvNovDaBwO49h5f5Lp7Cjxcs5NLEhm5/fqlVz/Xbr0K+4241YJXqrPbO8cVc8LXlUC+jf+gAakbGUzlOiJtYzcyhW5mStIsz4gsZFIGBeG/FCE6IL2RmfO93kLcMv54IPZ/x80LdQH7x4VcZ/oLg/WAjdkP3Q1Qp0ODrFofXiyQlYnKzqR6fSuVYB82jGzk1fzdfG/ApU7z7yXF68MjRIyL6wuK6VC5LPNhn+79yx3k0zE9nyJNFPJzXtV6Irf56vrf1G9Q9O5jsd/YQKNrXw1Uq1Q96dcPJbmqCpiY4WE7yOkgOLa9wuXg8bQqPDh9EzagkqkY5aB7fyFkjt3FJ5mecEHeAwa7eDcRKq4Fcl91noVdpNTAlrZCHfjacBTlPAMfeaVRpNfCXypN56rVzyH+5Ds+aAuIChQR6rVql2qbB10UmEMA6WB4MxNVfBOI+l4tHMk/DzhtA7YgkqkY7aRjtY2L+fmZnr+fcxK0Mc8V1O6wOWvVMXfJjFlzwNNA3h4dL6ofzRvFEVn7lPrKPoafcbyw+aIrjB6u/Sc5zXpLe20x+TbCVGNnHGaq/00PdPiIuF46kRBicQ+3YdCrHOqkf1cyk0UVcmbOaafGF5DndJDjavwuaZWx2BxqY/ff/YvgfPmPzvcex/ZKH+uT6xYNWPddtv4rXx77e5jp1dhPrmuP4/d6L2PXqCIb+c1+wQyTCf85U/6Pn+CKZw4kzNQUzJIe6kalUjXJSN76ZKWN2cVHW54yIK2WbbyCL9k9h5/pcMtcJGetq4PMtmEAAV+5gTnitiN/krO+Tcs/8/KssmbCQdOfRw+HurRjBC3efT/rKYqyiYp3eSoWVBl80cjhxpqcicXGY5masyuo2R0/4LpzCggcf4ESPp9fLurdiBGO9+7k4oenwsmq7kRmrbmDoHU1YW3f0eg09QgRatpKNra3Sfqa94Ivd8V2RzrawyisIFB/AKq9od8iY583VXPX8bfj7YM6H85I28XL5KYdf7/LXcWPhReT+wRk9oedwsvP300j/MPXwv73/mEjl9dNxThyLIzm5489QUU07N/oDYxh9zxYumXopb477V6/uaqI7jtqAB8vYfNYc4N/1x7Ng6Gv8/dETeXjtGQzOrgJg/7YBDPxISFtdgl24L7IOe6dO5OWr72ViXIshdPngm+5np9/PG3XH8fiW6SQtSSHz9a3BTizVr+ihbj9ipp/A7c880+sXM//swEmM9JYyzlPMGd5Amx0rPuNnrc/BgyXnsGLZRAZ9ZJG0upBASWlYDyt9F09hycP34xUXW/wWg51Wq+O5G+xmHqkewwOvX8io52vhs82YgF6AEy30HF8Mabx8KsfftY4/Df5Pr13ft7TRyX1FX+GV0W92ars6u4kX6/K4b9u5+P6TRd7SGmRLIXZtba/U2RZnZgZb7xiLHW8z7r4yyk7P4fFf/i/Hx3nb3GZjcyPzN38TeXQASXsaMG3cYcFZ34y1aWvHwd6iU6t+RAr1OU68lYa0j/YQKO7kbDiqVRp8McaZmcGum8fxx2v/dkQnRE+pthv5S8WJ/DxrS5c/wzI2ewINPFd9Cgufm8mQe1b1bWvqUOeGbSEuFynLUlk8YmmHmy2oHM65iZsZ6Gw9mHYH4rjmP/OxfU4G51WQ4Pa3ul68y88VOWs4LX7X4cuYfMbPu43J/HrLJSTfm4LrvTXa4dINGnwxSk6aSMmvLN45+fEenZrr9pITWfzJFD6c9b/kuTo/A8uXHbTqmX3nT0h9ZkXHK/cGEXYvmsTaGY91eB3l78tHMzt5/ZHnB1tR0NzASzUnMTiukiuT9nxp1pqOfebzcfWi2xj1xy3Bzi3VadqrG6PM2o3kXL2Li3/+U+4+OK5HPrPBbubdh6Yz9gdrufpnP+WeipHd/swsZyL1A8P4o2gMI7+7mykP3sayxvbrmJ28nrsKL+ehqlwa7LY7bMbHJfDzrC1M8RbyWPU49gTqOlXSiR4PG697gIxXbQLnnhJsoaoeoy2+GOEakkfBT/N4+bIF7Z7Lao/fWJy/6Qrir6rCqqoGwHH8ODIfOsA12SuY4inHjbR6cXN7tvrr+f68W3C/+2mX6upR046n9M5mlp3yd1IdbbfqVvn8vF07idMTt7bbwQPBc5vP1Izk5PjdTPW0f9611KrnscqTAbgoeT2pDj8lVjzXLbqZUfdsxqqs7NrXFYP0UFcFiWDPOAH3/y3ljmGvM9BZT57TjVucHU639amvmW88cysj7z36l8+RkIAjJRlrSDZ2nJOK8fFYHqF6vAVJAaaO3kWis+3W0UdvHc+wXy2PmPNZDq+XAzeczK03v8D1KaVtruc3FksbE2g2TqZ4ShnUzmG/ZWxebUhhgLOGGd6jQ3Krv55r1n+b+kYP5+Zv46YB75PssHim6hT+seskqisTid/qYdiDGw//0WmTCI6kJGTIIKqPy6BivANXI+SsaiJuQyFWRVVMdJ5o8KkjOBITcaSlYmel4stJpDbPTUOO0DDcT3xmI9PzdjMyoYyzkgrIcDTxy6JLqPjvYTiXre1aODmciKPtQzVjWRETei25Rgxn86/TWX72A+1OyuAzfv5Ufhw/y9zU4R+QP1cO48rkjUeEZHGgjtOW3sovpv2LeakHjtrGMjaf+AwLir/CurfHMexfNfD5NozPB4T+8AzMpn78AIqnu0g6oZw5+Z8yO+lzRrjdh3v3S616Xq/PZ+G+Uylcmceg5RaJBWWRd51lD9HgU50i7jjE6cAxMBvjdkHJQayamnCXFRbiclF91WTG3bqRR4YsazXYXq5PYqCzmmnejiepLbXqebZmIrel7wa+CL2fnvo2N6XtPaaadvjr+OW+2Xy0fgyejEYuGbWBq9JXcZzbdNg501KD3cz6ZicPlpzDh+vGkfmJkwErK2Hnnn4xIawGn1Ld5MzMoHD+OH77nSeOmHXaMjafNltUWQk0GA8j3AcZ4aLNXly/sbinfAK3ZXyOR1ycsPJabhz3wTGHXm+yjM1WfxN/q5jBkq2TiF+exMCVdTh3FGMdPBiRrfL2aPAp1UNk8nHc8fyznB1/9F2RKq0G1jQns7x+NNWBYMfIUE8FFyRtYow7Eb+xWFg7iDPidzLSncSvyyaw9MBYPpj0Ul9/GcfEMjbFVgPvNQzngR3nULtyANlrAySt3Udg/4GIP0+owadUD3EkJND4cjZLJ754THMg7gnU8Wb9GD6pyWdDxUD+d+xipnmdlFr1nPraj/j3xfcytAeuhewrdXYT/2lK5f69M9m8fig5KyB9dSlm34GIOzzWqeeV6iF2QwOJc5uY9ugcnjruCYa5XK2eV/vM5+Nv5aezvXYAk9L247OdlK/L5uMho5nm3clXPr2BS6asjarQg+Ah/KwEH7PGvg5jwXeln3XN8HLVKSxaN4X05XFkrm/AVbC7497nMNIWn1Jd4Bo+lKlLtuMUm1RnIxbCtPgdDHM10mDgzfrxXJZUwKAWN1S3jI1THGz113PpEz9jzbwFneqMiAaHDo9fqD2OhzedgfPTZHI+8eFZv6fD6dV6mrb4lOphpqoar8PP7ZnbsIxNud3I3oCb52uPwyt+5qfuxi1HtuYOBWCyGBATcbcq7QlOcZDnSuK29N3cNmM3zAie+3yrIZdniqexZeVwBq6wSd54ELuw6PAlOX1Ng0+pLrBq6njok7O4cuZaRrqTyHYmku2EUzy7Q2u0HWrZzgR8OQEaTDOp0v6Y3/4g3ZnAnORK5iS/AWOg4ZvNFPjhkbKzeHvtFNLXushZUQ3bCrHr6/ukJj3UVaqLxOUicPrxFP/QxyuTH2ak+9jP14354DpemvZwh5MdxALL2OwINPJU5TRe2HoicSuTGbi8HteOYqyy8i4fHmuvrlK9qGUAvjvl4XaHrh0yb8/p3Drw3S6Pm+7vigN1fNiUywO7zqV0xSCy1lukflqMVbT/mKcv0+BTqg+Iy0XFknxWnfSPDte9t2IED64/k8/OfKjTU1bFoga7mVU+L/fvm8ln60YwYJWDzFVlmL3727yMRjs3lOoDJhCgbvkAKo9v6HCGmh9n7GTP2AzO+PR6Vk9+tk/uixzNEhxxnB1vc/aod2AU+K+w2Ngc4IXqyTy3YTKpH3nJ/LwRd8EerIrKDkeZdLvFJyJOYDWwzxgzW0QygOeB4cBu4GpjTGVo3TuBeYAF3GKMeaujz9cWn4omjuRk6s6bQPk361k0+bEOD2V/c3AshU0ZPJj7kYZfNxzqWX+5bjT/u2EmI35UwUd7n+rViUhvBQpavL4DWGqMGQ0sDb1GRCYAc4CJwCzgwVBoKtVv2LW1JLy0kiFXF3D75d9hzFM38lBVLj7T+hT0P8/awqiEUr6+83xerk9qcz3VPqc4yHYmMj91P69N/St2Rvu3CO1W8IlIHnAx8FiLxZcBT4aePwlc3mL5ImOMzxizC9gOTO3O/pWKWLaF/dkm8u9YzqvnHseMX93CBQWzKW5lJuafZezghkEf8pc953Dcv7/LzE2X8kp9goZgL+ruOb4FwH8BLeM1xxhTDGCMKRaR7NDyXKDlTRWKQsuOIiLzgfkAXjo3m69SkSZwoITMR0uQpzxce9ot7PimgwfOfoZZ8Q2HD29nJfiYNf5VfOOCNxxaUPgVflKSydDsCn454hXO1P6PHtXlFp+IzAZKjTHHOl94a8farZ5gNMY8YoyZbIyZ7MbT1RKViijG58P5/hrG3LCav1x4Ecc/cDM/2DeNg9YXF+16xM3FCU28M/5VNpz1KD8c9h7f/vjb2vrrYd051J0BXCoiu4FFwLki8gxQIiKDAEKPh+buLgKGtNg+D9jfjf0rFbWsbTvJ++3H7DrXzddu/BEnrLqGT31HzoLsETeXJ9YxfGA5bzWkhqnS/qnLwWeMudMYk2eMGU6w0+I9Y8y3gFeAuaHV5gJLQs9fAeaIiEdE8oHRwKouV65UP2DX1uJ9bRUDr9jKLy65jtFP3ci8Pafzg33TeKR6MCuaLE7O2MsfdswKd6n9Sm9cx/c7YLGIzAP2AFcBGGM2ishiYBMQAG4yxkT2TIZK9RXbwt6wmRF3wD5X8Ndyd+o4liScDLaN74IcfJP8h++fobpHR24oFQWcOdnELRZeHt3hpa8xb4e/jpsvuYHl6/6iNxRXKppZJaX453q4Zf+UcJfSL2jwKRUlArv3UHDbRB6pHhzuUqKeBp9SUcTxn8946r8vYX1zU7hLiWoafEpFmcR/ruI7/+9HrPLptX1dpcGnVLQxhszHV/HLr85lzFM3ck/FSL3AuZM0+JSKRi3GAr9/1jBm/OoWvlJwCTv8R48FVkfT4FMqylnlFWQ+uhznrBJuvOYmRrz0PV6uT8IyR9/0XAVp8CnVTxh/M/LxOkbfvIpHzz2bk/9wM9/YdQ6lVt/cwCeaaPAp1d8YQ2BvEQPv+5jKmY1cdeOPGL3sepY2OrUVGKLBp1Q/Zjc14X1tFSO+uY4/XXg5xz9wM3cfHEedHduXw2jwKRULjMHauoO8337Mx2fmcP5Pb+OkT+YcNSNMrNDgUyrGWFXVJC9aQfZXt3HXld9m1HPf5y9VQ2LqkhgNPqVilW1hPt3IyJ+s4F9njeOMu27h8m0XsKeV6fH7Gw0+pRRWWRnpTyyn6fwqvnPdLeS/+l0W1ab3284QDT6l1GHG58O5bA1jvvcJT59/OicuuJnv7p1xxPT4/YEGn1KqVYHCvQy+52OKzjFcOf82xv3nWj5q6h8tQA0+pVS77IYGPG98wrA5m/h/s+cw/pEf8POS42mwo7dHWINPKXVsbAtr01aG/upjPjsrjXPuvJXp674WlVNkafAppTrNqqkh7enlpF5SyH99bR6jnvs+T9Rk44+S2+ho8CmluswEAocvifnH2Scx/Vc3M2vzxRRF+CUxGnxKqR4ROFBC5qPL4YIyrvvOreS/eQMv1ydFZCtQg08p1aOMvxn3u58yZt6nPPqVcznlTz/kJ8UnU2k1hLu0wzT4lFK9wxgCu/cw6N6P2XRmPJfdHDmXxGjwKaV6nV1fT/ySVQz7+gbuvvwbjP37jWGdJUaDTynVd4zBXr+Z4Xct5+OzBnH+T29j5qZL2erv25EhGnxKqbCwKitJXrQC96z9/PDrNzJy8fd5qCq3TzpDNPiUUmFlAgFYsZ5Rt63g1ZmTmPrbH3LljvN69ZIYDT6lVMQIFB8g+4GPqTuvluvn3sLI977N2w3uHp8lRoNPKRVxjM+H8/01jLr2MxbMms0J99/M94qmU2039sjna/AppSKXMVjbd5H7+4/Zc46Di2+7jUkrv8Eqn79brUANPqVUVLDr60l8YSWDryjgV7O/xfinb2JB5fAuzRKjwaeUii7GYG3cQv4dy3n7rJGcc+etzFh/Bbv8x94Z4urF8pRSqldZB8tJe3o58pyL+dN/yPZr3Fw34yPo4ChYg08pFfVMIIDjw7WM+RBWD8zDVO5qd/1uHeqKSJqIvCAim0WkQESmi0iGiLwjIttCj+kt1r9TRLaLyBYRuaA7+1ZKqdYEDpRgfL521+nuOb77gDeNMeOAE4AC4A5gqTFmNLA09BoRmQDMASYCs4AHRcTZzf0rpVSndTn4RCQFOBN4HMAY02yMqQIuA54MrfYkcHno+WXAImOMzxizC9gOTO3q/pVSqqu60+IbAZQBfxeRtSLymIgkAjnGmGKA0GN2aP1cYG+L7YtCy44iIvNFZLWIrPbTfpNVKaU6qzvB5wJOBv5qjDkJqCd0WNsGaWWZaW1FY8wjxpjJxpjJbjzdKFEppY7WneArAoqMMStDr18gGIQlIjIIIPRY2mL9IS22zwP2d2P/SinVJV0OPmPMAWCviIwNLZoJbAJeAeaGls0FloSevwLMERGPiOQDo4FVXd2/Ukp1VXev4/shsFBE4oCdwLcJhuliEZkH7AGuAjDGbBSRxQTDMQDcZEwE3oVEKdXviTGtnmaLGCmSYU6VmeEuQykVZVaapdSYitb6FnSsrlIq9mjwKaVijgafUirmaPAppWKOBp9SKuZo8CmlYo4Gn1Iq5mjwKaVijgafUirmaPAppWKOBp9SKuZo8CmlYo4Gn1Iq5mjwKaVijgafUirmaPAppWKOBp9SKuZo8CmlYo4Gn1Iq5mjwKaVijgafUirmaPAppWKOBp9SKuZo8CmlYo4Gn1Iq5mjwKaVijgafUirmaPAppWKOBp9SKuZo8CmlYo4Gn1Iq5mjwKaVijgafUirmdCv4RORHIrJRRDaIyHMi4hWRDBF5R0S2hR7TW6x/p4hsF5EtInJB98tXSqnO63LwiUgucAsw2RhzHOAE5gB3AEuNMaOBpaHXiMiE0PsTgVnAgyLi7F75SinVed091HUB8SLiAhKA/cBlwJOh958ELg89vwxYZIzxGWN2AduBqd3cv1JKdVqXg88Ysw/4I7AHKAaqjTFvAznGmOLQOsVAdmiTXGBvi48oCi07iojMF5HVIrLaj6+rJSqlVKu6c6ibTrAVlw8MBhJF5FvtbdLKMtPaisaYR4wxk40xk914ulqiUkq1qjuHuucBu4wxZcYYP/AicBpQIiKDAEKPpaH1i4AhLbbPI3horJRSfao7wbcHmCYiCSIiwEygAHgFmBtaZy6wJPT8FWCOiHhEJB8YDazqxv6VUqpLXF3d0BizUkReANYAAWAt8AiQBCwWkXkEw/Gq0PobRWQxsCm0/k3GGKub9SulVKeJMa2eZosYKZJhTpWZ4S5DKRVlVpql1JiK1voWdOSGUir2aPAppWKOBp9SKuZo8CmlYo4Gn1Iq5mjwKaVijgafUirmaPAppWJOl0duKBUNXEPyqDwt75jWdViGpN31YB3bRf3Oqjrs0oPYDQ3QBwMBxOPBmZWJlZ1Ow9BEGjOc1A9u9frcL2r0Q9JeG7GDrx0BQ1LhF1+jWBZSXI5pasKubwA7NgZTafCpfs0keKmdU0Oip7nDdW2g3HZgH2OGNTUn0VA1gLhiN8m7IfvjcqyCbT0Tgg4nzgGZNE/Ioy43jpp8B425AbyZjSR4fTgdlTjFkHIMH2X4YhokGyizvjjQM0aobxyEv9GNVLmJP+DAe9CQVBwgfm8t4gsgTT7siqrg9v0kHDX4VFQRlwucwYm7xenEkZEO0narxxhDXUkSiUMrjunznQ6bY50W3B3vIzneB4OAk6HwQg+O5dMZ8vR2rJLSDrf/MkdiIoweRsXxqZRPAkdeA6nJdTgdNilwTCF3THU77SNexyU3QDLBmTPHBJc1ATUBJ8a48Pm9+BqzMEaQg3E4mgVXk5BQbBAbUnc249mwF6u0rE9avj1Bx+qqiCDuOPxnTqJ+oPuI5YF4OeJwzpdpYxJCLQ6HIT61CYej/Z/hOFeAOFfftVJKDqSRtiaO1B1+EnZWQkkZVk1dhy2lptlTqfluDR53oI8q7RmW7aCqJgHX1gRyVvpJWFMYESHY3lhdbfGp8BLBMXEsO69JJ3FSxVEB5QJSw1NZl+UMrIKLoMEIFX43dTUjcR7wkLRHvgjD4lKs2tojwsF2S9SFHgRbyZlpdTC1joYpwr7qwbi2joqoEPwybfGpsHJOGMPOX3lIS2oMdyl9wjZCk99FXU08riIP6ZshfWMNjp37CUwYRuFF8cf+WU5w5NeTntzQixV3nW2EyupE3AUJDH2tGvPZpj4NQG3xqYhVckYmaUll4S6jzzjEkBDnJyHLD1nAiVAacFJdMxxnkRdHx30wh6Vth4yXofi0bOzTq0ny9t79aarq4gn4XdgHPXgPOoirBuOAuqE2zsENJCc2HXXu0CEm2BKcXkfRSR4c/5nOkH/uJVC4t429hIjg8HhwpKVifM1YVVU9Hpja4lNh40xPp+CekeQMrgp3KVHJNsLB8mQGvh6HWIbGa6t69FymbYTyiiQy3veSvayY+nEDODjJjXGAhGIjaa9N8p5g4FaP9FI1FsywxmDgtaKsIpnMd7xkvbQRq6am1XVk8nFsmR+PN70Jf7ML95Z4Bq1oxvNRAXZ9/THX316LT4NPhU3dVafiv74Ch0T2z2Ck8/ldJP89hdKTXKRN6XxvcmtKy1LI+MBD9gcl1E3IYt85DlLyq1o9B9nQ7Ka2OJmUzS4GrqzDdaCKA+fnUn1WE1nptUetbxuhrDCdUc/7cX68EeM/spnbfMFk6m+pPuLnwrIdlBemk//PAO4PPz9qm9Zo8KmI40xLpeAPY8jJqwx3Kf1CaVkKI56AXfMMAzKODpvOqKhJYPh9QtXYBMrO8JOVU4PTYXe8IdDY7KaxII3hrzTgLq7kwAW5VJ/ZegD6/C4aP8tgxOJyrE1bDx/Olt8wHdcVrZ/+8PldNGxIZ+TCjq+Z1OBTEafhq6fSNK/ymH+hVMcq1w4gdStw9cFutaIb38nGdkLiuV1vPR4VgO20AGsavHiWpTD4pd0E9u2n6OenkXx6+/uubfTgWJHK0OcKCRTta3Ud7dxQEac5yaGh18OSji/HsSmDyrr4Lvf0VtYmkF1oUfmt1s/RHav4OD/xJ5RRMt5N46ZcRvyjhoFv17J/dh6+s2tISWg6vG5KQhNc1ETB5EEMeSEPX7ohuYPPT473wTmlbDlpAFmvDyHjX1uwKo/96EGDT4WFwzKt301edZnbaSMGAvsSYFzXgs+9JoniGTZZPdRDHB/nJ/7EMvZPcNO0KZfhr9Xj/CDA3ouysScfGYDZ2dWUnZSNnd3UziceKSutDvuaegrOGsWwFyH+/c+xmzreXoNPqQhg2cHxs91uBRtwBNqfuKAtFdWJDNhlEzej58+7JsT5STixjJIJbho3pQcD8PUjA9A2QtIeQ2BC53qmHWLIya2k9gcOis49iVHP12LWFEA7H6PBp1SYVVQnMvjpOLxlTdQNS6BhgIOmTKEp28IkB0hIacIb58fpML3aAx7wuYgvbaapF/dxqAVYMsFN3c40hrzrx/uOYe/52TRNbGRIWQBffCcuZmzB7bTJmljG/l+4SXviFHjp7TbX1eBTKozqfXEMe8iB49+fYIDETyAx9J64XIjHgyM9DWtQBk1ZXuoGu2gaIPjSDYHsZjyJzXjiAvgDTppKEhle5seK7+KvtcNA1xqLnRYf5yd+3EFqRzvYszudoW/4SVhST/2ItG4P20uI81Of0/5UExp8KiySC5so87uicmxqTwqsS8Px4cpW3zOBACYQCF60W7QPD+A59KYIjvh4HOlpmAQv0tSMdWArjsR45PoRXarF4bKx4vo2EtxOm+yR5dTe6GDPrnTiKp2k9cF1nRp8KiwcqzZRt/kUPJNiZ7jal9X74hj2ajWmK/PbGYPd0BCcBPUIxz7W98sSE3z40rxd3r473E6b7FHlfbY/nXpehYXxNzP8tSZ8/tj92+tfnwbrtvTsh7pcSAfTdLXHYRmM6aPj3TDS4FNh41y1ibrN6eEuIyzqfXEMf6UaE+jZQ/2600eSntK1S1lcTgt3nU3l/mibCKzzNPhU2Bifj5Ev1FFW0dHlqv2HbYSSfemkPZ2MWbu51XWcKSk4U1LA4Wx3dumjtsvJZu8ldpcviXE7bUqmuEn/7FjnoI5czSntf99i9zhDRQTzyeeM/e1YNn8/k+yRfXeOp6/ZRijbn8bgtx2Mf2czVlV1q+s5vF42/98JSIYPyj3EVTmIq4TkfRZxNRbewiqkvhG7sgrj833RYhSh+MpRDBjYvXOm1nF1pD/s5kCjJzg6Ikr5Mts/3NfgU2FnbdzCuLuz2f3dUSROOxj1Q9n8loOmZjeNtV6cpXEk7BdSCi3Gvx8MvPa6MowxJBQ7qPe68ObWkzTKh9NhEwCajVAZcNHUnIGvIQepiMNVLyQWgXEITWfX4ulmj2h6cgM1wwbQvD0O+nHHkwafighWSSnD7q3j4JwTqJpVR3KCr0cD8NDIiENsA42+OCzryOVWwIldEXfkxga8ZU5cXzp15miGlL0B5EtJllrWhOtAFXbZ7iNuPXksfbfG5yP3dx/j8HpxDMjCPzSL6pHx1OUKjXkW7qxGkhKaSE1shAGhjU4OPnja/NTOOXiGn+HPw564LAaMPdhDnxpZdHYWFVkcTlyDcvCNGUj5RC81o2zshKMjQ5oceMucfHnAb+J+g6vxyIXuRpuEoqPvfessrcY0fmnKe8vGqm5lgswIuKWiuONwZKRhD8mmNj+R2iFO6ofYSLaP5KRG3C6rx0Z2lB5MYfgzDgovdEVl+FWsH0Dp7Xfr7CwqStgWgX37ce7bT/b7kONygbTSB2fsTvWIthYH0XbptPE3B29bWVJK0mpIIji6w5GagsnNJpCeREN2HE3pDupzhUCijT2gGbc3gNfjx+MOHHMwZmfVsPtbKQx/JkAh/a/l12HwicjfgNlAqTHmuNCyDOB5YDiwG7jaGFMZeu9OYB7Blv0txpi3QstPAZ4geIXl68CtJtKbmyrsevpyj/7GBAJY5RVQXoGDYBgmEbydBw4njngvjuQkTEoSvrw0/ClOaoa6aE4BX9aRpxKMgGT6cIbuneFyW+ye7Wb0sw1s/3p0hZ/p4HqVY2nxPQE8ADzVYtkdwFJjzO9E5I7Q69tFZAIwB5gIDAbeFZExxhgL+CswH1hBMPhmAW905otRSnWCbWHX1weHvB0owbU1+At/eGyH4+jLVpwpSUe1sO2GBsYVprPzeyNwn1hJQpy/10vvLiu7GXG0nX4dXsdnjPkA+PJt6C8Dngw9fxK4vMXyRcYYnzFmF7AdmCoig4AUY8zyUCvvqRbbKKXCwbaO+mdVVWNVVh7xz/h8BIoPMOzuVeT8yUvpjkzsSB/d0cHola5ewJxjjCkGCD1mh5bnAi3vHVcUWpYbev7l5a0SkfkislpEVvuJ3muJlOpPTCCA48O1jLurANdTmVF94XlPj9xo7c+AaWd5q4wxjxhjJhtjJrt7rJNeKdUTrJoakp9fwbg7Sql/P5vaxuj7He1q8JWEDl8JPR66M0gRMKTFennA/tDyvFaWK6WiVKBoH4P/uJwhd0P55wOOulYyknW10leAuaHnc4ElLZbPERGPiOQDo4FVocPhWhGZJiICXNdiG6VUtDIGs3Yjo365lsS/plKyPy3yz/9xbJezPAecDWSJSBHwS+B3wGIRmQfsAa4CMMZsFJHFwCaCl0ndFOrRBbiRLy5neQPt0VWq37CbmvD86xPGr8ykcfIILE94w294o02FaXvkT8SP3BCRWqCHJy3rFVlAtFzoFC21RkudED21Rkud0P1aRwPLjTGzvvxGNIzc2GKMmRzuIjoiIqujoU6InlqjpU6InlqjpU7o3Vqj52ykUkr1EA0+pVTMiYbgeyTcBRyjaKkToqfWaKkToqfWaKkTerHWiO/cUEqpnhYNLT6llOpRGnxKqZgTscEnIrNEZIuIbA9NfRXOWoaIyPsiUiAiG0Xk1tDyDBF5R0S2hR7TW2xzZ6j2LSJyQRhqdorIWhF5LVJrFZE0EXlBRDaHvrfTI7HO0L5/FPq/3yAiz4mIN1JqFZG/iUipiGxosazTtYnIKSLyeei9+0OjrHq7zntC///rReQlEUnrkzqNMRH3D3ACO4ARQBywDpgQxnoGASeHnicDW4EJwB+AO0LL7wB+H3o+IVSzB8gPfS3OPq75x8CzwGuh1xFXK8EpzW4IPY8D0iK0zlxgFxAfer0YuD5SagXOJHjnjQ0tlnW6NmAVMJ3gpCJvABf2QZ3nA67Q89/3VZ2R2uKbCmw3xuw0xjQDiwjO9RcWxphiY8ya0PNaoIDgL0On5iXsq3pFJA+4GHisxeKIqlVEUgj+IjwOYIxpNsZURVqdLbiAeBFxAQkEJ9mIiFpNlMyZ2Vqdxpi3jTGHptlewReTmfRqnZEafG3N6xd2IjIcOAlYSefnJewrC4D/AloOVoy0WkcAZcDfQ4fkj4lIYgTWiTFmH/BHguPSi4FqY8zbkVhrC706Z2Yv+Q5fjOHv1TojNfg6NX9fXxGRJOCfwG3GmFZuxfXFqq0s65P6ReTQ/VE+PdZNWlnWF7W6CB72/NUYcxJQT/CQrC3h/J6mE2yB5BO8pUKiiHyrvU1aWRb2n9+QHpkzs6eJyF0EJzZZeGhRG/X0SJ2RGnxtzesXNiLiJhh6C40xL4YWd3Zewr4wA7hURHYTPEVwrog8E4G1FgFFxpiVodcvEAzCSKsT4DxglzGmzBjjB14ETovQWg+JmjkzRWQuwRuafTN0+NrrdUZq8H0CjBaRfBGJI3gDo1fCVUyo1+hxoMAYc2+Ltzo1L2Ff1GqMudMYk2eMGU7w+/aeMeZbkVarMeYAsFdExoYWzSQ4nVlE1RmyB5gmIgmhn4WZBM/zRmKth0TFnJkiMgu4HbjUGNPylu29W2dv9TT1QA/QRQR7T3cAd4W5ltMJNqfXA5+F/l0EZAJLgW2hx4wW29wVqn0LPdw71om6z+aLXt2IqxU4EVgd+r6+DKRHYp2hff8a2AxsAJ4m2NsYEbUCzxE89+gn2CKa15XagMmhr28HwTsrSh/UuZ3gubxDv1cP9UWdOmRNKRVzIvVQVymleo0Gn1Iq5mjwKaVijgafUirmaPAppWKOBp9SKuZo8CmlYs7/B+NLlHL+JF7VAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mask[0][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 3], device='cuda:0'), tensor([0, 2, 3]))"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prd.unique(), mask.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x250400aad90>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(prd.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "23d8489b17aa989cee42bd3f3e82cc035b4cfa42fa1ea343caf5051171f57614"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('datasci': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
