{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from cv2 import cv2\n",
    "import os\n",
    "import natsort\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import ToPILImage\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "from feelvos.transform import preprocessing\n",
    "\n",
    "\n",
    "class FEELVOSTriple(Dataset):\n",
    "    def __init__(self, root='./data/', split='train', transform=None):\n",
    "        super().__init__()\n",
    "        self.root = root\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        self.folder_list = []\n",
    "        self.items = []\n",
    "\n",
    "        folder_f = open(os.path.join(root, self.split+\"_folder_list.txt\"), \"r\")\n",
    "        for x in folder_f:\n",
    "            self.folder_list.append(x[:-1])\n",
    "\n",
    "        for i in range(len(self.folder_list)):\n",
    "            tmp_list = natsort.natsorted(os.listdir(os.path.join(root, 'image', self.folder_list[i])))\n",
    "            for j in range(len(tmp_list) - 2):\n",
    "                first = tmp_list[j]\n",
    "                for k in range(len(tmp_list[j+1:])-1):\n",
    "                    comb_1 = tmp_list[k+1]\n",
    "                    comb_2 = tmp_list[k+2]\n",
    "                    self.items.append((os.path.join(self.root, 'image', self.folder_list[i], first), os.path.join(self.root, 'image', self.folder_list[i], comb_1), os.path.join(self.root, 'image', self.folder_list[i], comb_2)))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        src = []\n",
    "        mask = []\n",
    "        seltem = self.items[index]\n",
    "        for i in range(3):\n",
    "            src.append(cv2.imread(seltem[i]))\n",
    "            mask.append(cv2.imread(os.path.join(seltem[i].split('/')[1], 'mask', seltem[i].split('/')[3], seltem[i].split('/')[4])))\n",
    "        sample = (src, mask)\n",
    "        if self.transform is None:\n",
    "            pass\n",
    "        else:\n",
    "            sample = self.transform(*sample)\n",
    "        if self.split == 'train':\n",
    "            sample[0][0] = sample[1][0]\n",
    "            sample[0][1] = sample[1][1]\n",
    "        return sample\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ds_train = FEELVOSTriple(root='./data/', split='train', transform=preprocessing)\n",
    "    ds_test = FEELVOSTriple(root='./data/', split='test', transform=preprocessing)\n",
    "    print(\"DATA LOADED\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
