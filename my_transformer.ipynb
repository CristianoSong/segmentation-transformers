{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Toy Transformer \r\n",
    "This file has been created to understand the attention/transformer structure and basic method to build transformer in PyTorch.  \""
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 0. Preparation - package import"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import os\r\n",
    "import json\r\n",
    "import torch\r\n",
    "import random\r\n",
    "import cv2\r\n",
    "import numpy as np\r\n",
    "import torchvision\r\n",
    "from pathlib import Path\r\n",
    "from torch import nn\r\n",
    "import torch.utils.data as Data\r\n",
    "from torch.utils.data import Dataset\r\n",
    "from torch.nn.utils.rnn import pad_sequence\r\n",
    "from torch.nn import functional as F\r\n",
    "from torchvision import models, transforms\r\n",
    "import matplotlib.pyplot as plt \r\n",
    "import matplotlib\r\n",
    "\r\n",
    "%matplotlib inline\r\n",
    "\r\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Dataset and Dataloader\r\n",
    "### Train / valid split based on the **folds** argument"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data_path = Path(\"C:/Users/Siyao/Downloads/EndoVis2017Data\")\r\n",
    "train_path = data_path / \"cropped_train\"\r\n",
    "\r\n",
    "def get_split(fold):\r\n",
    "    \"\"\"Split train and valid dataset based on the No. of folder\"\"\"\r\n",
    "    folds = {0: [1, 3],\r\n",
    "             1: [2, 5],\r\n",
    "             2: [4, 8],\r\n",
    "             3: [6, 7]}\r\n",
    "    train_path = data_path / 'cropped_train'\r\n",
    "\r\n",
    "    train_file_names = []\r\n",
    "    val_file_names = []\r\n",
    "\r\n",
    "    for instrument_id in range(1, 9):\r\n",
    "        if instrument_id in folds[fold]:\r\n",
    "            val_file_names += list((train_path / ('instrument_dataset_' + str(instrument_id)) / 'images').glob('*'))\r\n",
    "        else:\r\n",
    "            train_file_names += list((train_path / ('instrument_dataset_' + str(instrument_id)) / 'images').glob('*'))\r\n",
    "\r\n",
    "    return train_file_names, val_file_names\r\n",
    "\r\n",
    "train_file_names, val_file_names = get_split(0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Function to load image or mask"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def load_image(path):\r\n",
    "    img = cv2.imread(str(path))\r\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\r\n",
    "\r\n",
    "binary_factor = 255\r\n",
    "parts_factor = 85\r\n",
    "instrument_factor = 32\r\n",
    "\r\n",
    "def load_mask(path, problem_type=\"instruments\", mask_folder=\"instruments_masks\",factor=instrument_factor):\r\n",
    "    if problem_type == 'binary':\r\n",
    "        mask_folder = 'binary_masks'\r\n",
    "        factor = binary_factor\r\n",
    "    elif problem_type == 'parts':\r\n",
    "        mask_folder = 'parts_masks'\r\n",
    "        factor = parts_factor\r\n",
    "    elif problem_type == 'instruments':\r\n",
    "        factor = instrument_factor\r\n",
    "        mask_folder = 'instruments_masks'\r\n",
    "\r\n",
    "    mask = cv2.imread(str(path).replace('images', mask_folder).replace('jpg', 'png'), 0)\r\n",
    "\r\n",
    "    return (mask / factor).astype(np.uint8)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dataset for training and validation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class RoboticsDataset(Dataset):\r\n",
    "    \"\"\"Dataset that only loads single frame\"\"\"\r\n",
    "\r\n",
    "    def __init__(self, file_names, to_augment=False, transform=None, mode='train', problem_type=None):\r\n",
    "        self.file_names = file_names\r\n",
    "        self.to_augment = to_augment\r\n",
    "        self.transform = transform\r\n",
    "        self.mode = mode\r\n",
    "        self.problem_type = problem_type\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        return len(self.file_names)\r\n",
    "\r\n",
    "    def __getitem__(self, idx):\r\n",
    "        img_file_name = self.file_names[idx]\r\n",
    "        image = load_image(img_file_name)\r\n",
    "        mask = load_mask(img_file_name, self.problem_type)\r\n",
    "\r\n",
    "        # data = {\"image\": image, \"mask\": mask}\r\n",
    "        # augmented = self.transform(**data)\r\n",
    "        # image, mask = augmented[\"image\"], augmented[\"mask\"]\r\n",
    "\r\n",
    "        # if self.mode == 'train':\r\n",
    "        if self.problem_type == 'binary':\r\n",
    "            return torch.from_numpy(image), torch.from_numpy(np.expand_dims(mask, 0)).float(), str(img_file_name)\r\n",
    "        else:\r\n",
    "            return torch.from_numpy(image), torch.from_numpy(mask).long(), str(img_file_name)\r\n",
    "        # else:\r\n",
    "        #     return torch.from_numpy(image), str(img_file_name)\r\n",
    "\r\n",
    "train_data_single = RoboticsDataset(train_file_names, problem_type=\"instrument\")\r\n",
    "valid_data_single = RoboticsDataset(val_file_names, mode='valid')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Instrument Dataset\r\n",
    "1. Mutiple image stacked as data\r\n",
    "2. The label used instrument type"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "### Creating the lists of file name, that starts from tau frames after the first frame\r\n",
    "### which avoid the first few frames having no previous frames issue.\r\n",
    "\r\n",
    "tau = 3\r\n",
    "train_img_path = [str(i) for i in train_file_names]\r\n",
    "train_frame_name = [i for i in train_img_path if int(i[-7:-4])>=tau]\r\n",
    "valid_img_path = [str(i) for i in val_file_names] \r\n",
    "valid_frame_name = [i for i in valid_img_path if int(i[-7:-4])>=tau]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## RESIZE IMAGE TO 1/16 RESOLUTION\r\n",
    "class InstrumentDataset(Dataset):\r\n",
    "    \"\"\"Dataset that loads multiple frame\"\"\"\r\n",
    "\r\n",
    "    def __init__(self, file_names, problem_type=\"Instrument\", tau=3):\r\n",
    "        self.file_names = file_names\r\n",
    "        self.problem_type = problem_type\r\n",
    "        self.tau = tau      # tau is the number of frames should be combiend\r\n",
    "        self.transform = transforms.Compose([\r\n",
    "                                transforms.ToPILImage(),\r\n",
    "                                # transforms.Resize([256,320]),\r\n",
    "                                transforms.ToTensor()\r\n",
    "                            ]) \r\n",
    "    def __len__(self):\r\n",
    "        return len(self.file_names)\r\n",
    "\r\n",
    "    def __getitem__(self, idx):\r\n",
    "        current_frame = self.file_names[idx]\r\n",
    "        mask = load_mask(current_frame, self.problem_type)\r\n",
    "        frames_ls = []\r\n",
    "        for i in range(tau):\r\n",
    "            to_find = \"frame\"+current_frame[-7:-4]\r\n",
    "            to_repl = \"frame\"+ '%03d' % (int(current_frame[-7:-4])-i)\r\n",
    "            frame = current_frame.replace(to_find, to_repl)\r\n",
    "            frame_array = load_image(frame)\r\n",
    "            frame_tensor = self.transform(frame_array)\r\n",
    "            # frame_tensor = torch.from_numpy(frame_tensor)            \r\n",
    "            frames_ls.append(frame_tensor)\r\n",
    "        frames_stack = torch.stack(frames_ls, 0)\r\n",
    "        # permute the tensor from [tau, H, W, C] to [tau, C, H, W]\r\n",
    "        # frames_tensor = frames_stack.permute(0,3,1,2)\r\n",
    "        return frames_stack.float(), torch.from_numpy(mask).float(), str(current_frame) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "### Traning and validation data with multi-frames input\r\n",
    "# The data in 4D tensor (tau, H, W, C), label in 3D tensor ()\r\n",
    "training_data_frames = InstrumentDataset(train_frame_name)\r\n",
    "valid_data_frames = InstrumentDataset(valid_frame_name)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dataloader"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "batch_size = 1\r\n",
    "training_data_loader = Data.DataLoader(training_data_frames, batch_size=batch_size, shuffle=True)\r\n",
    "valid_data_loader = Data.DataLoader(valid_data_frames, batch_size=batch_size, shuffle=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "a,b,c = next(iter(training_data_loader))\r\n",
    "print(f\"Data shape: {a.shape}\")\r\n",
    "print(f\"Mask shape: {b.shape}\")\r\n",
    "print(f\"Path: {c}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "img = a[0][0].permute(1,2,0)\r\n",
    "plt.imshow(img)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model\r\n",
    "### CNN Backbone"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# model = models.segmentation.fcn_resnet101(pretrained=True).eval()\r\n",
    "model = models.resnet101(pretrained=True).eval()\r\n",
    "model.to(device)\r\n",
    "# y = model(a[0].to(device))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (12): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (13): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (14): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (15): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (16): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (17): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (18): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (19): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (20): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (21): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (22): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from torchinfo import summary\r\n",
    "summary(model, input_size=(3,3,224, 320))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ResNet                                   --                        --\n",
       "├─Conv2d: 1-1                            [3, 64, 112, 160]         9,408\n",
       "├─BatchNorm2d: 1-2                       [3, 64, 112, 160]         128\n",
       "├─ReLU: 1-3                              [3, 64, 112, 160]         --\n",
       "├─MaxPool2d: 1-4                         [3, 64, 56, 80]           --\n",
       "├─Sequential: 1-5                        [3, 256, 56, 80]          --\n",
       "│    └─Bottleneck: 2-1                   [3, 256, 56, 80]          --\n",
       "│    │    └─Conv2d: 3-1                  [3, 64, 56, 80]           4,096\n",
       "│    │    └─BatchNorm2d: 3-2             [3, 64, 56, 80]           128\n",
       "│    │    └─ReLU: 3-3                    [3, 64, 56, 80]           --\n",
       "│    │    └─Conv2d: 3-4                  [3, 64, 56, 80]           36,864\n",
       "│    │    └─BatchNorm2d: 3-5             [3, 64, 56, 80]           128\n",
       "│    │    └─ReLU: 3-6                    [3, 64, 56, 80]           --\n",
       "│    │    └─Conv2d: 3-7                  [3, 256, 56, 80]          16,384\n",
       "│    │    └─BatchNorm2d: 3-8             [3, 256, 56, 80]          512\n",
       "│    │    └─Sequential: 3-9              [3, 256, 56, 80]          16,896\n",
       "│    │    └─ReLU: 3-10                   [3, 256, 56, 80]          --\n",
       "│    └─Bottleneck: 2-2                   [3, 256, 56, 80]          --\n",
       "│    │    └─Conv2d: 3-11                 [3, 64, 56, 80]           16,384\n",
       "│    │    └─BatchNorm2d: 3-12            [3, 64, 56, 80]           128\n",
       "│    │    └─ReLU: 3-13                   [3, 64, 56, 80]           --\n",
       "│    │    └─Conv2d: 3-14                 [3, 64, 56, 80]           36,864\n",
       "│    │    └─BatchNorm2d: 3-15            [3, 64, 56, 80]           128\n",
       "│    │    └─ReLU: 3-16                   [3, 64, 56, 80]           --\n",
       "│    │    └─Conv2d: 3-17                 [3, 256, 56, 80]          16,384\n",
       "│    │    └─BatchNorm2d: 3-18            [3, 256, 56, 80]          512\n",
       "│    │    └─ReLU: 3-19                   [3, 256, 56, 80]          --\n",
       "│    └─Bottleneck: 2-3                   [3, 256, 56, 80]          --\n",
       "│    │    └─Conv2d: 3-20                 [3, 64, 56, 80]           16,384\n",
       "│    │    └─BatchNorm2d: 3-21            [3, 64, 56, 80]           128\n",
       "│    │    └─ReLU: 3-22                   [3, 64, 56, 80]           --\n",
       "│    │    └─Conv2d: 3-23                 [3, 64, 56, 80]           36,864\n",
       "│    │    └─BatchNorm2d: 3-24            [3, 64, 56, 80]           128\n",
       "│    │    └─ReLU: 3-25                   [3, 64, 56, 80]           --\n",
       "│    │    └─Conv2d: 3-26                 [3, 256, 56, 80]          16,384\n",
       "│    │    └─BatchNorm2d: 3-27            [3, 256, 56, 80]          512\n",
       "│    │    └─ReLU: 3-28                   [3, 256, 56, 80]          --\n",
       "├─Sequential: 1-6                        [3, 512, 28, 40]          --\n",
       "│    └─Bottleneck: 2-4                   [3, 512, 28, 40]          --\n",
       "│    │    └─Conv2d: 3-29                 [3, 128, 56, 80]          32,768\n",
       "│    │    └─BatchNorm2d: 3-30            [3, 128, 56, 80]          256\n",
       "│    │    └─ReLU: 3-31                   [3, 128, 56, 80]          --\n",
       "│    │    └─Conv2d: 3-32                 [3, 128, 28, 40]          147,456\n",
       "│    │    └─BatchNorm2d: 3-33            [3, 128, 28, 40]          256\n",
       "│    │    └─ReLU: 3-34                   [3, 128, 28, 40]          --\n",
       "│    │    └─Conv2d: 3-35                 [3, 512, 28, 40]          65,536\n",
       "│    │    └─BatchNorm2d: 3-36            [3, 512, 28, 40]          1,024\n",
       "│    │    └─Sequential: 3-37             [3, 512, 28, 40]          132,096\n",
       "│    │    └─ReLU: 3-38                   [3, 512, 28, 40]          --\n",
       "│    └─Bottleneck: 2-5                   [3, 512, 28, 40]          --\n",
       "│    │    └─Conv2d: 3-39                 [3, 128, 28, 40]          65,536\n",
       "│    │    └─BatchNorm2d: 3-40            [3, 128, 28, 40]          256\n",
       "│    │    └─ReLU: 3-41                   [3, 128, 28, 40]          --\n",
       "│    │    └─Conv2d: 3-42                 [3, 128, 28, 40]          147,456\n",
       "│    │    └─BatchNorm2d: 3-43            [3, 128, 28, 40]          256\n",
       "│    │    └─ReLU: 3-44                   [3, 128, 28, 40]          --\n",
       "│    │    └─Conv2d: 3-45                 [3, 512, 28, 40]          65,536\n",
       "│    │    └─BatchNorm2d: 3-46            [3, 512, 28, 40]          1,024\n",
       "│    │    └─ReLU: 3-47                   [3, 512, 28, 40]          --\n",
       "│    └─Bottleneck: 2-6                   [3, 512, 28, 40]          --\n",
       "│    │    └─Conv2d: 3-48                 [3, 128, 28, 40]          65,536\n",
       "│    │    └─BatchNorm2d: 3-49            [3, 128, 28, 40]          256\n",
       "│    │    └─ReLU: 3-50                   [3, 128, 28, 40]          --\n",
       "│    │    └─Conv2d: 3-51                 [3, 128, 28, 40]          147,456\n",
       "│    │    └─BatchNorm2d: 3-52            [3, 128, 28, 40]          256\n",
       "│    │    └─ReLU: 3-53                   [3, 128, 28, 40]          --\n",
       "│    │    └─Conv2d: 3-54                 [3, 512, 28, 40]          65,536\n",
       "│    │    └─BatchNorm2d: 3-55            [3, 512, 28, 40]          1,024\n",
       "│    │    └─ReLU: 3-56                   [3, 512, 28, 40]          --\n",
       "│    └─Bottleneck: 2-7                   [3, 512, 28, 40]          --\n",
       "│    │    └─Conv2d: 3-57                 [3, 128, 28, 40]          65,536\n",
       "│    │    └─BatchNorm2d: 3-58            [3, 128, 28, 40]          256\n",
       "│    │    └─ReLU: 3-59                   [3, 128, 28, 40]          --\n",
       "│    │    └─Conv2d: 3-60                 [3, 128, 28, 40]          147,456\n",
       "│    │    └─BatchNorm2d: 3-61            [3, 128, 28, 40]          256\n",
       "│    │    └─ReLU: 3-62                   [3, 128, 28, 40]          --\n",
       "│    │    └─Conv2d: 3-63                 [3, 512, 28, 40]          65,536\n",
       "│    │    └─BatchNorm2d: 3-64            [3, 512, 28, 40]          1,024\n",
       "│    │    └─ReLU: 3-65                   [3, 512, 28, 40]          --\n",
       "├─Sequential: 1-7                        [3, 1024, 14, 20]         --\n",
       "│    └─Bottleneck: 2-8                   [3, 1024, 14, 20]         --\n",
       "│    │    └─Conv2d: 3-66                 [3, 256, 28, 40]          131,072\n",
       "│    │    └─BatchNorm2d: 3-67            [3, 256, 28, 40]          512\n",
       "│    │    └─ReLU: 3-68                   [3, 256, 28, 40]          --\n",
       "│    │    └─Conv2d: 3-69                 [3, 256, 14, 20]          589,824\n",
       "│    │    └─BatchNorm2d: 3-70            [3, 256, 14, 20]          512\n",
       "│    │    └─ReLU: 3-71                   [3, 256, 14, 20]          --\n",
       "│    │    └─Conv2d: 3-72                 [3, 1024, 14, 20]         262,144\n",
       "│    │    └─BatchNorm2d: 3-73            [3, 1024, 14, 20]         2,048\n",
       "│    │    └─Sequential: 3-74             [3, 1024, 14, 20]         526,336\n",
       "│    │    └─ReLU: 3-75                   [3, 1024, 14, 20]         --\n",
       "│    └─Bottleneck: 2-9                   [3, 1024, 14, 20]         --\n",
       "│    │    └─Conv2d: 3-76                 [3, 256, 14, 20]          262,144\n",
       "│    │    └─BatchNorm2d: 3-77            [3, 256, 14, 20]          512\n",
       "│    │    └─ReLU: 3-78                   [3, 256, 14, 20]          --\n",
       "│    │    └─Conv2d: 3-79                 [3, 256, 14, 20]          589,824\n",
       "│    │    └─BatchNorm2d: 3-80            [3, 256, 14, 20]          512\n",
       "│    │    └─ReLU: 3-81                   [3, 256, 14, 20]          --\n",
       "│    │    └─Conv2d: 3-82                 [3, 1024, 14, 20]         262,144\n",
       "│    │    └─BatchNorm2d: 3-83            [3, 1024, 14, 20]         2,048\n",
       "│    │    └─ReLU: 3-84                   [3, 1024, 14, 20]         --\n",
       "│    └─Bottleneck: 2-10                  [3, 1024, 14, 20]         --\n",
       "│    │    └─Conv2d: 3-85                 [3, 256, 14, 20]          262,144\n",
       "│    │    └─BatchNorm2d: 3-86            [3, 256, 14, 20]          512\n",
       "│    │    └─ReLU: 3-87                   [3, 256, 14, 20]          --\n",
       "│    │    └─Conv2d: 3-88                 [3, 256, 14, 20]          589,824\n",
       "│    │    └─BatchNorm2d: 3-89            [3, 256, 14, 20]          512\n",
       "│    │    └─ReLU: 3-90                   [3, 256, 14, 20]          --\n",
       "│    │    └─Conv2d: 3-91                 [3, 1024, 14, 20]         262,144\n",
       "│    │    └─BatchNorm2d: 3-92            [3, 1024, 14, 20]         2,048\n",
       "│    │    └─ReLU: 3-93                   [3, 1024, 14, 20]         --\n",
       "│    └─Bottleneck: 2-11                  [3, 1024, 14, 20]         --\n",
       "│    │    └─Conv2d: 3-94                 [3, 256, 14, 20]          262,144\n",
       "│    │    └─BatchNorm2d: 3-95            [3, 256, 14, 20]          512\n",
       "│    │    └─ReLU: 3-96                   [3, 256, 14, 20]          --\n",
       "│    │    └─Conv2d: 3-97                 [3, 256, 14, 20]          589,824\n",
       "│    │    └─BatchNorm2d: 3-98            [3, 256, 14, 20]          512\n",
       "│    │    └─ReLU: 3-99                   [3, 256, 14, 20]          --\n",
       "│    │    └─Conv2d: 3-100                [3, 1024, 14, 20]         262,144\n",
       "│    │    └─BatchNorm2d: 3-101           [3, 1024, 14, 20]         2,048\n",
       "│    │    └─ReLU: 3-102                  [3, 1024, 14, 20]         --\n",
       "│    └─Bottleneck: 2-12                  [3, 1024, 14, 20]         --\n",
       "│    │    └─Conv2d: 3-103                [3, 256, 14, 20]          262,144\n",
       "│    │    └─BatchNorm2d: 3-104           [3, 256, 14, 20]          512\n",
       "│    │    └─ReLU: 3-105                  [3, 256, 14, 20]          --\n",
       "│    │    └─Conv2d: 3-106                [3, 256, 14, 20]          589,824\n",
       "│    │    └─BatchNorm2d: 3-107           [3, 256, 14, 20]          512\n",
       "│    │    └─ReLU: 3-108                  [3, 256, 14, 20]          --\n",
       "│    │    └─Conv2d: 3-109                [3, 1024, 14, 20]         262,144\n",
       "│    │    └─BatchNorm2d: 3-110           [3, 1024, 14, 20]         2,048\n",
       "│    │    └─ReLU: 3-111                  [3, 1024, 14, 20]         --\n",
       "│    └─Bottleneck: 2-13                  [3, 1024, 14, 20]         --\n",
       "│    │    └─Conv2d: 3-112                [3, 256, 14, 20]          262,144\n",
       "│    │    └─BatchNorm2d: 3-113           [3, 256, 14, 20]          512\n",
       "│    │    └─ReLU: 3-114                  [3, 256, 14, 20]          --\n",
       "│    │    └─Conv2d: 3-115                [3, 256, 14, 20]          589,824\n",
       "│    │    └─BatchNorm2d: 3-116           [3, 256, 14, 20]          512\n",
       "│    │    └─ReLU: 3-117                  [3, 256, 14, 20]          --\n",
       "│    │    └─Conv2d: 3-118                [3, 1024, 14, 20]         262,144\n",
       "│    │    └─BatchNorm2d: 3-119           [3, 1024, 14, 20]         2,048\n",
       "│    │    └─ReLU: 3-120                  [3, 1024, 14, 20]         --\n",
       "│    └─Bottleneck: 2-14                  [3, 1024, 14, 20]         --\n",
       "│    │    └─Conv2d: 3-121                [3, 256, 14, 20]          262,144\n",
       "│    │    └─BatchNorm2d: 3-122           [3, 256, 14, 20]          512\n",
       "│    │    └─ReLU: 3-123                  [3, 256, 14, 20]          --\n",
       "│    │    └─Conv2d: 3-124                [3, 256, 14, 20]          589,824\n",
       "│    │    └─BatchNorm2d: 3-125           [3, 256, 14, 20]          512\n",
       "│    │    └─ReLU: 3-126                  [3, 256, 14, 20]          --\n",
       "│    │    └─Conv2d: 3-127                [3, 1024, 14, 20]         262,144\n",
       "│    │    └─BatchNorm2d: 3-128           [3, 1024, 14, 20]         2,048\n",
       "│    │    └─ReLU: 3-129                  [3, 1024, 14, 20]         --\n",
       "│    └─Bottleneck: 2-15                  [3, 1024, 14, 20]         --\n",
       "│    │    └─Conv2d: 3-130                [3, 256, 14, 20]          262,144\n",
       "│    │    └─BatchNorm2d: 3-131           [3, 256, 14, 20]          512\n",
       "│    │    └─ReLU: 3-132                  [3, 256, 14, 20]          --\n",
       "│    │    └─Conv2d: 3-133                [3, 256, 14, 20]          589,824\n",
       "│    │    └─BatchNorm2d: 3-134           [3, 256, 14, 20]          512\n",
       "│    │    └─ReLU: 3-135                  [3, 256, 14, 20]          --\n",
       "│    │    └─Conv2d: 3-136                [3, 1024, 14, 20]         262,144\n",
       "│    │    └─BatchNorm2d: 3-137           [3, 1024, 14, 20]         2,048\n",
       "│    │    └─ReLU: 3-138                  [3, 1024, 14, 20]         --\n",
       "│    └─Bottleneck: 2-16                  [3, 1024, 14, 20]         --\n",
       "│    │    └─Conv2d: 3-139                [3, 256, 14, 20]          262,144\n",
       "│    │    └─BatchNorm2d: 3-140           [3, 256, 14, 20]          512\n",
       "│    │    └─ReLU: 3-141                  [3, 256, 14, 20]          --\n",
       "│    │    └─Conv2d: 3-142                [3, 256, 14, 20]          589,824\n",
       "│    │    └─BatchNorm2d: 3-143           [3, 256, 14, 20]          512\n",
       "│    │    └─ReLU: 3-144                  [3, 256, 14, 20]          --\n",
       "│    │    └─Conv2d: 3-145                [3, 1024, 14, 20]         262,144\n",
       "│    │    └─BatchNorm2d: 3-146           [3, 1024, 14, 20]         2,048\n",
       "│    │    └─ReLU: 3-147                  [3, 1024, 14, 20]         --\n",
       "│    └─Bottleneck: 2-17                  [3, 1024, 14, 20]         --\n",
       "│    │    └─Conv2d: 3-148                [3, 256, 14, 20]          262,144\n",
       "│    │    └─BatchNorm2d: 3-149           [3, 256, 14, 20]          512\n",
       "│    │    └─ReLU: 3-150                  [3, 256, 14, 20]          --\n",
       "│    │    └─Conv2d: 3-151                [3, 256, 14, 20]          589,824\n",
       "│    │    └─BatchNorm2d: 3-152           [3, 256, 14, 20]          512\n",
       "│    │    └─ReLU: 3-153                  [3, 256, 14, 20]          --\n",
       "│    │    └─Conv2d: 3-154                [3, 1024, 14, 20]         262,144\n",
       "│    │    └─BatchNorm2d: 3-155           [3, 1024, 14, 20]         2,048\n",
       "│    │    └─ReLU: 3-156                  [3, 1024, 14, 20]         --\n",
       "│    └─Bottleneck: 2-18                  [3, 1024, 14, 20]         --\n",
       "│    │    └─Conv2d: 3-157                [3, 256, 14, 20]          262,144\n",
       "│    │    └─BatchNorm2d: 3-158           [3, 256, 14, 20]          512\n",
       "│    │    └─ReLU: 3-159                  [3, 256, 14, 20]          --\n",
       "│    │    └─Conv2d: 3-160                [3, 256, 14, 20]          589,824\n",
       "│    │    └─BatchNorm2d: 3-161           [3, 256, 14, 20]          512\n",
       "│    │    └─ReLU: 3-162                  [3, 256, 14, 20]          --\n",
       "│    │    └─Conv2d: 3-163                [3, 1024, 14, 20]         262,144\n",
       "│    │    └─BatchNorm2d: 3-164           [3, 1024, 14, 20]         2,048\n",
       "│    │    └─ReLU: 3-165                  [3, 1024, 14, 20]         --\n",
       "│    └─Bottleneck: 2-19                  [3, 1024, 14, 20]         --\n",
       "│    │    └─Conv2d: 3-166                [3, 256, 14, 20]          262,144\n",
       "│    │    └─BatchNorm2d: 3-167           [3, 256, 14, 20]          512\n",
       "│    │    └─ReLU: 3-168                  [3, 256, 14, 20]          --\n",
       "│    │    └─Conv2d: 3-169                [3, 256, 14, 20]          589,824\n",
       "│    │    └─BatchNorm2d: 3-170           [3, 256, 14, 20]          512\n",
       "│    │    └─ReLU: 3-171                  [3, 256, 14, 20]          --\n",
       "│    │    └─Conv2d: 3-172                [3, 1024, 14, 20]         262,144\n",
       "│    │    └─BatchNorm2d: 3-173           [3, 1024, 14, 20]         2,048\n",
       "│    │    └─ReLU: 3-174                  [3, 1024, 14, 20]         --\n",
       "│    └─Bottleneck: 2-20                  [3, 1024, 14, 20]         --\n",
       "│    │    └─Conv2d: 3-175                [3, 256, 14, 20]          262,144\n",
       "│    │    └─BatchNorm2d: 3-176           [3, 256, 14, 20]          512\n",
       "│    │    └─ReLU: 3-177                  [3, 256, 14, 20]          --\n",
       "│    │    └─Conv2d: 3-178                [3, 256, 14, 20]          589,824\n",
       "│    │    └─BatchNorm2d: 3-179           [3, 256, 14, 20]          512\n",
       "│    │    └─ReLU: 3-180                  [3, 256, 14, 20]          --\n",
       "│    │    └─Conv2d: 3-181                [3, 1024, 14, 20]         262,144\n",
       "│    │    └─BatchNorm2d: 3-182           [3, 1024, 14, 20]         2,048\n",
       "│    │    └─ReLU: 3-183                  [3, 1024, 14, 20]         --\n",
       "│    └─Bottleneck: 2-21                  [3, 1024, 14, 20]         --\n",
       "│    │    └─Conv2d: 3-184                [3, 256, 14, 20]          262,144\n",
       "│    │    └─BatchNorm2d: 3-185           [3, 256, 14, 20]          512\n",
       "│    │    └─ReLU: 3-186                  [3, 256, 14, 20]          --\n",
       "│    │    └─Conv2d: 3-187                [3, 256, 14, 20]          589,824\n",
       "│    │    └─BatchNorm2d: 3-188           [3, 256, 14, 20]          512\n",
       "│    │    └─ReLU: 3-189                  [3, 256, 14, 20]          --\n",
       "│    │    └─Conv2d: 3-190                [3, 1024, 14, 20]         262,144\n",
       "│    │    └─BatchNorm2d: 3-191           [3, 1024, 14, 20]         2,048\n",
       "│    │    └─ReLU: 3-192                  [3, 1024, 14, 20]         --\n",
       "│    └─Bottleneck: 2-22                  [3, 1024, 14, 20]         --\n",
       "│    │    └─Conv2d: 3-193                [3, 256, 14, 20]          262,144\n",
       "│    │    └─BatchNorm2d: 3-194           [3, 256, 14, 20]          512\n",
       "│    │    └─ReLU: 3-195                  [3, 256, 14, 20]          --\n",
       "│    │    └─Conv2d: 3-196                [3, 256, 14, 20]          589,824\n",
       "│    │    └─BatchNorm2d: 3-197           [3, 256, 14, 20]          512\n",
       "│    │    └─ReLU: 3-198                  [3, 256, 14, 20]          --\n",
       "│    │    └─Conv2d: 3-199                [3, 1024, 14, 20]         262,144\n",
       "│    │    └─BatchNorm2d: 3-200           [3, 1024, 14, 20]         2,048\n",
       "│    │    └─ReLU: 3-201                  [3, 1024, 14, 20]         --\n",
       "│    └─Bottleneck: 2-23                  [3, 1024, 14, 20]         --\n",
       "│    │    └─Conv2d: 3-202                [3, 256, 14, 20]          262,144\n",
       "│    │    └─BatchNorm2d: 3-203           [3, 256, 14, 20]          512\n",
       "│    │    └─ReLU: 3-204                  [3, 256, 14, 20]          --\n",
       "│    │    └─Conv2d: 3-205                [3, 256, 14, 20]          589,824\n",
       "│    │    └─BatchNorm2d: 3-206           [3, 256, 14, 20]          512\n",
       "│    │    └─ReLU: 3-207                  [3, 256, 14, 20]          --\n",
       "│    │    └─Conv2d: 3-208                [3, 1024, 14, 20]         262,144\n",
       "│    │    └─BatchNorm2d: 3-209           [3, 1024, 14, 20]         2,048\n",
       "│    │    └─ReLU: 3-210                  [3, 1024, 14, 20]         --\n",
       "│    └─Bottleneck: 2-24                  [3, 1024, 14, 20]         --\n",
       "│    │    └─Conv2d: 3-211                [3, 256, 14, 20]          262,144\n",
       "│    │    └─BatchNorm2d: 3-212           [3, 256, 14, 20]          512\n",
       "│    │    └─ReLU: 3-213                  [3, 256, 14, 20]          --\n",
       "│    │    └─Conv2d: 3-214                [3, 256, 14, 20]          589,824\n",
       "│    │    └─BatchNorm2d: 3-215           [3, 256, 14, 20]          512\n",
       "│    │    └─ReLU: 3-216                  [3, 256, 14, 20]          --\n",
       "│    │    └─Conv2d: 3-217                [3, 1024, 14, 20]         262,144\n",
       "│    │    └─BatchNorm2d: 3-218           [3, 1024, 14, 20]         2,048\n",
       "│    │    └─ReLU: 3-219                  [3, 1024, 14, 20]         --\n",
       "│    └─Bottleneck: 2-25                  [3, 1024, 14, 20]         --\n",
       "│    │    └─Conv2d: 3-220                [3, 256, 14, 20]          262,144\n",
       "│    │    └─BatchNorm2d: 3-221           [3, 256, 14, 20]          512\n",
       "│    │    └─ReLU: 3-222                  [3, 256, 14, 20]          --\n",
       "│    │    └─Conv2d: 3-223                [3, 256, 14, 20]          589,824\n",
       "│    │    └─BatchNorm2d: 3-224           [3, 256, 14, 20]          512\n",
       "│    │    └─ReLU: 3-225                  [3, 256, 14, 20]          --\n",
       "│    │    └─Conv2d: 3-226                [3, 1024, 14, 20]         262,144\n",
       "│    │    └─BatchNorm2d: 3-227           [3, 1024, 14, 20]         2,048\n",
       "│    │    └─ReLU: 3-228                  [3, 1024, 14, 20]         --\n",
       "│    └─Bottleneck: 2-26                  [3, 1024, 14, 20]         --\n",
       "│    │    └─Conv2d: 3-229                [3, 256, 14, 20]          262,144\n",
       "│    │    └─BatchNorm2d: 3-230           [3, 256, 14, 20]          512\n",
       "│    │    └─ReLU: 3-231                  [3, 256, 14, 20]          --\n",
       "│    │    └─Conv2d: 3-232                [3, 256, 14, 20]          589,824\n",
       "│    │    └─BatchNorm2d: 3-233           [3, 256, 14, 20]          512\n",
       "│    │    └─ReLU: 3-234                  [3, 256, 14, 20]          --\n",
       "│    │    └─Conv2d: 3-235                [3, 1024, 14, 20]         262,144\n",
       "│    │    └─BatchNorm2d: 3-236           [3, 1024, 14, 20]         2,048\n",
       "│    │    └─ReLU: 3-237                  [3, 1024, 14, 20]         --\n",
       "│    └─Bottleneck: 2-27                  [3, 1024, 14, 20]         --\n",
       "│    │    └─Conv2d: 3-238                [3, 256, 14, 20]          262,144\n",
       "│    │    └─BatchNorm2d: 3-239           [3, 256, 14, 20]          512\n",
       "│    │    └─ReLU: 3-240                  [3, 256, 14, 20]          --\n",
       "│    │    └─Conv2d: 3-241                [3, 256, 14, 20]          589,824\n",
       "│    │    └─BatchNorm2d: 3-242           [3, 256, 14, 20]          512\n",
       "│    │    └─ReLU: 3-243                  [3, 256, 14, 20]          --\n",
       "│    │    └─Conv2d: 3-244                [3, 1024, 14, 20]         262,144\n",
       "│    │    └─BatchNorm2d: 3-245           [3, 1024, 14, 20]         2,048\n",
       "│    │    └─ReLU: 3-246                  [3, 1024, 14, 20]         --\n",
       "│    └─Bottleneck: 2-28                  [3, 1024, 14, 20]         --\n",
       "│    │    └─Conv2d: 3-247                [3, 256, 14, 20]          262,144\n",
       "│    │    └─BatchNorm2d: 3-248           [3, 256, 14, 20]          512\n",
       "│    │    └─ReLU: 3-249                  [3, 256, 14, 20]          --\n",
       "│    │    └─Conv2d: 3-250                [3, 256, 14, 20]          589,824\n",
       "│    │    └─BatchNorm2d: 3-251           [3, 256, 14, 20]          512\n",
       "│    │    └─ReLU: 3-252                  [3, 256, 14, 20]          --\n",
       "│    │    └─Conv2d: 3-253                [3, 1024, 14, 20]         262,144\n",
       "│    │    └─BatchNorm2d: 3-254           [3, 1024, 14, 20]         2,048\n",
       "│    │    └─ReLU: 3-255                  [3, 1024, 14, 20]         --\n",
       "│    └─Bottleneck: 2-29                  [3, 1024, 14, 20]         --\n",
       "│    │    └─Conv2d: 3-256                [3, 256, 14, 20]          262,144\n",
       "│    │    └─BatchNorm2d: 3-257           [3, 256, 14, 20]          512\n",
       "│    │    └─ReLU: 3-258                  [3, 256, 14, 20]          --\n",
       "│    │    └─Conv2d: 3-259                [3, 256, 14, 20]          589,824\n",
       "│    │    └─BatchNorm2d: 3-260           [3, 256, 14, 20]          512\n",
       "│    │    └─ReLU: 3-261                  [3, 256, 14, 20]          --\n",
       "│    │    └─Conv2d: 3-262                [3, 1024, 14, 20]         262,144\n",
       "│    │    └─BatchNorm2d: 3-263           [3, 1024, 14, 20]         2,048\n",
       "│    │    └─ReLU: 3-264                  [3, 1024, 14, 20]         --\n",
       "│    └─Bottleneck: 2-30                  [3, 1024, 14, 20]         --\n",
       "│    │    └─Conv2d: 3-265                [3, 256, 14, 20]          262,144\n",
       "│    │    └─BatchNorm2d: 3-266           [3, 256, 14, 20]          512\n",
       "│    │    └─ReLU: 3-267                  [3, 256, 14, 20]          --\n",
       "│    │    └─Conv2d: 3-268                [3, 256, 14, 20]          589,824\n",
       "│    │    └─BatchNorm2d: 3-269           [3, 256, 14, 20]          512\n",
       "│    │    └─ReLU: 3-270                  [3, 256, 14, 20]          --\n",
       "│    │    └─Conv2d: 3-271                [3, 1024, 14, 20]         262,144\n",
       "│    │    └─BatchNorm2d: 3-272           [3, 1024, 14, 20]         2,048\n",
       "│    │    └─ReLU: 3-273                  [3, 1024, 14, 20]         --\n",
       "├─Sequential: 1-8                        [3, 2048, 7, 10]          --\n",
       "│    └─Bottleneck: 2-31                  [3, 2048, 7, 10]          --\n",
       "│    │    └─Conv2d: 3-274                [3, 512, 14, 20]          524,288\n",
       "│    │    └─BatchNorm2d: 3-275           [3, 512, 14, 20]          1,024\n",
       "│    │    └─ReLU: 3-276                  [3, 512, 14, 20]          --\n",
       "│    │    └─Conv2d: 3-277                [3, 512, 7, 10]           2,359,296\n",
       "│    │    └─BatchNorm2d: 3-278           [3, 512, 7, 10]           1,024\n",
       "│    │    └─ReLU: 3-279                  [3, 512, 7, 10]           --\n",
       "│    │    └─Conv2d: 3-280                [3, 2048, 7, 10]          1,048,576\n",
       "│    │    └─BatchNorm2d: 3-281           [3, 2048, 7, 10]          4,096\n",
       "│    │    └─Sequential: 3-282            [3, 2048, 7, 10]          2,101,248\n",
       "│    │    └─ReLU: 3-283                  [3, 2048, 7, 10]          --\n",
       "│    └─Bottleneck: 2-32                  [3, 2048, 7, 10]          --\n",
       "│    │    └─Conv2d: 3-284                [3, 512, 7, 10]           1,048,576\n",
       "│    │    └─BatchNorm2d: 3-285           [3, 512, 7, 10]           1,024\n",
       "│    │    └─ReLU: 3-286                  [3, 512, 7, 10]           --\n",
       "│    │    └─Conv2d: 3-287                [3, 512, 7, 10]           2,359,296\n",
       "│    │    └─BatchNorm2d: 3-288           [3, 512, 7, 10]           1,024\n",
       "│    │    └─ReLU: 3-289                  [3, 512, 7, 10]           --\n",
       "│    │    └─Conv2d: 3-290                [3, 2048, 7, 10]          1,048,576\n",
       "│    │    └─BatchNorm2d: 3-291           [3, 2048, 7, 10]          4,096\n",
       "│    │    └─ReLU: 3-292                  [3, 2048, 7, 10]          --\n",
       "│    └─Bottleneck: 2-33                  [3, 2048, 7, 10]          --\n",
       "│    │    └─Conv2d: 3-293                [3, 512, 7, 10]           1,048,576\n",
       "│    │    └─BatchNorm2d: 3-294           [3, 512, 7, 10]           1,024\n",
       "│    │    └─ReLU: 3-295                  [3, 512, 7, 10]           --\n",
       "│    │    └─Conv2d: 3-296                [3, 512, 7, 10]           2,359,296\n",
       "│    │    └─BatchNorm2d: 3-297           [3, 512, 7, 10]           1,024\n",
       "│    │    └─ReLU: 3-298                  [3, 512, 7, 10]           --\n",
       "│    │    └─Conv2d: 3-299                [3, 2048, 7, 10]          1,048,576\n",
       "│    │    └─BatchNorm2d: 3-300           [3, 2048, 7, 10]          4,096\n",
       "│    │    └─ReLU: 3-301                  [3, 2048, 7, 10]          --\n",
       "├─AdaptiveAvgPool2d: 1-9                 [3, 2048, 1, 1]           --\n",
       "├─Linear: 1-10                           [3, 1000]                 2,049,000\n",
       "==========================================================================================\n",
       "Total params: 44,549,160\n",
       "Trainable params: 44,549,160\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 396.05\n",
       "==========================================================================================\n",
       "Input size (MB): 2.58\n",
       "Forward/backward pass size (MB): 1113.07\n",
       "Params size (MB): 178.20\n",
       "Estimated Total Size (MB): 1293.85\n",
       "=========================================================================================="
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class CNNBackbone(nn.Module):\r\n",
    "    def __init__(self, c_in=3, n_out=2048):\r\n",
    "        super(CNNBackbone, self).__init__()\r\n",
    "        self.c_in = c_in\r\n",
    "        self.n_out = n_out\r\n",
    "        self.cnn = models.resnet101(pretrained=True).eval()\r\n",
    "        self.cnn.fc = nn.Linear(2048,self.n_out)\r\n",
    "    \r\n",
    "    def forward(self, x):\r\n",
    "        y = self.cnn(x[0])\r\n",
    "        out = y.unsqueeze(0)\r\n",
    "        # out.shape = [batch_size, tau, 2048]\r\n",
    "        return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Position Encoding"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class PositionEmbeddingSine(nn.Module):\r\n",
    "    \"\"\"\r\n",
    "    ## https://github.com/Epiphqny/VisTR/blob/master/models/position_encoding.py\r\n",
    "    This is a more standard version of the position embedding, very similar to the one\r\n",
    "    used by the Attention is all you need paper, generalized to work on images.\r\n",
    "    \"\"\"\r\n",
    "    def __init__(self, num_pos_feats=64, num_frames = 3, temperature=10000, normalize=False, scale=None):\r\n",
    "        super().__init__()\r\n",
    "        self.num_pos_feats = num_pos_feats\r\n",
    "        self.temperature = temperature\r\n",
    "        self.normalize = normalize\r\n",
    "        self.frames = num_frames\r\n",
    "        if scale is not None and normalize is False:\r\n",
    "            raise ValueError(\"normalize should be True if scale is passed\")\r\n",
    "        if scale is None:\r\n",
    "            scale = 2 * math.pi\r\n",
    "        self.scale = scale\r\n",
    "\r\n",
    "    def forward(self, tensor_list: NestedTensor):\r\n",
    "        x = tensor_list.tensors\r\n",
    "        mask = tensor_list.mask\r\n",
    "        n,h,w = mask.shape\r\n",
    "        mask = mask.reshape(n//self.frames, self.frames,h,w)\r\n",
    "        assert mask is not None\r\n",
    "        not_mask = ~mask\r\n",
    "        z_embed = not_mask.cumsum(1, dtype=torch.float32)\r\n",
    "        y_embed = not_mask.cumsum(2, dtype=torch.float32)\r\n",
    "        x_embed = not_mask.cumsum(3, dtype=torch.float32)\r\n",
    "        if self.normalize:\r\n",
    "            eps = 1e-6\r\n",
    "            z_embed = z_embed / (z_embed[:, -1:, :, :] + eps) * self.scale\r\n",
    "            y_embed = y_embed / (y_embed[:, :, -1:, :] + eps) * self.scale\r\n",
    "            x_embed = x_embed / (x_embed[:, :, :, -1:] + eps) * self.scale\r\n",
    "\r\n",
    "        dim_t = torch.arange(self.num_pos_feats, dtype=torch.float32, device=x.device)\r\n",
    "        dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)\r\n",
    "\r\n",
    "        pos_x = x_embed[:, :, :, :, None] / dim_t\r\n",
    "        pos_y = y_embed[:, :, :, :, None] / dim_t\r\n",
    "        pos_z = z_embed[:, :, :, :, None] / dim_t\r\n",
    "        pos_x = torch.stack((pos_x[:, :, :, :, 0::2].sin(), pos_x[:, :, :, :, 1::2].cos()), dim=5).flatten(4)\r\n",
    "        pos_y = torch.stack((pos_y[:, :, :, :, 0::2].sin(), pos_y[:, :, :, :, 1::2].cos()), dim=5).flatten(4)\r\n",
    "        pos_z = torch.stack((pos_z[:, :, :, :, 0::2].sin(), pos_z[:, :, :, :, 1::2].cos()), dim=5).flatten(4)\r\n",
    "        pos = torch.cat((pos_z, pos_y, pos_x), dim=4).permute(0, 1, 4, 2, 3)\r\n",
    "        return pos\r\n",
    "\r\n",
    "    N_steps = args.hidden_dim // 3\r\n",
    "    if args.position_embedding in ('v2', 'sine'):\r\n",
    "        # TODO find a better way of exposing other arguments\r\n",
    "        position_embedding = PositionEmbeddingSine(N_steps, num_frames = args.num_frames, normalize=True)\r\n",
    "    else:\r\n",
    "        raise ValueError(f\"not supported {args.position_embedding}\")\r\n",
    "\r\n",
    "    return position_embedding"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def clones(module, N):\r\n",
    "    \"Produce N identical layers; stack N modules.\"\r\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "### Define sparse attention \r\n",
    "# https://github.com/wilson1yan/VideoGPT/blob/master/videogpt/attention.py\r\n",
    "class SparseAttention(nn.Module):\r\n",
    "    ops = dict()\r\n",
    "    attn_mask = dict()\r\n",
    "    block_layout = dict()\r\n",
    "\r\n",
    "    def __init__(self, shape, n_head, causal, num_local_blocks=4, block=32,\r\n",
    "                 attn_dropout=0.): # does not use attn_dropout\r\n",
    "        super().__init__()\r\n",
    "        self.causal = causal\r\n",
    "        self.shape = shape\r\n",
    "\r\n",
    "        self.sparsity_config = StridedSparsityConfig(shape=shape, n_head=n_head,\r\n",
    "                                                     causal=causal, block=block,\r\n",
    "                                                     num_local_blocks=num_local_blocks)\r\n",
    "\r\n",
    "        if self.shape not in SparseAttention.block_layout:\r\n",
    "            SparseAttention.block_layout[self.shape] = self.sparsity_config.make_layout()\r\n",
    "        if causal and self.shape not in SparseAttention.attn_mask:\r\n",
    "            SparseAttention.attn_mask[self.shape] = self.sparsity_config.make_sparse_attn_mask()\r\n",
    "\r\n",
    "    def get_ops(self):\r\n",
    "        try:\r\n",
    "            from deepspeed.ops.sparse_attention import MatMul, Softmax\r\n",
    "        except:\r\n",
    "            raise Exception('Error importing deepspeed. Please install using `DS_BUILD_SPARSE_ATTN=1 pip install deepspeed`')\r\n",
    "        if self.shape not in SparseAttention.ops:\r\n",
    "            sparsity_layout = self.sparsity_config.make_layout()\r\n",
    "            sparse_dot_sdd_nt = MatMul(sparsity_layout,\r\n",
    "                                       self.sparsity_config.block,\r\n",
    "                                       'sdd',\r\n",
    "                                       trans_a=False,\r\n",
    "                                       trans_b=True)\r\n",
    "\r\n",
    "            sparse_dot_dsd_nn = MatMul(sparsity_layout,\r\n",
    "                                       self.sparsity_config.block,\r\n",
    "                                       'dsd',\r\n",
    "                                       trans_a=False,\r\n",
    "                                       trans_b=False)\r\n",
    "\r\n",
    "            sparse_softmax = Softmax(sparsity_layout, self.sparsity_config.block)\r\n",
    "\r\n",
    "            SparseAttention.ops[self.shape] = (sparse_dot_sdd_nt,\r\n",
    "                                               sparse_dot_dsd_nn,\r\n",
    "                                               sparse_softmax)\r\n",
    "        return SparseAttention.ops[self.shape]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class MultiHeadAttention(nn.Module):\r\n",
    "    def __init__(self, shape, dim_q, dim_v, n_head, n_layer, \r\n",
    "                        causal=True, attn_type=\"Sparse\", attn_kwargs):\r\n",
    "        super().__init__\r\n",
    "        self.causal = causal\r\n",
    "        self.shape = shape\r\n",
    "\r\n",
    "        self.d_k = dim_q // n_head\r\n",
    "        self.d_v = dim_v // n_head\r\n",
    "        self.n_head = n_head\r\n",
    "\r\n",
    "        self.w_qs = nn.Linear(dim_q, n_head * self.d_k, bias=False) # q\r\n",
    "        self.w_qs.weight.data.normal_(std=1.0 / np.sqrt(dim_q))\r\n",
    "\r\n",
    "        self.w_ks = nn.Linear(dim_kv, n_head * self.d_k, bias=False) # k\r\n",
    "        self.w_ks.weight.data.normal_(std=1.0 / np.sqrt(dim_kv))\r\n",
    "\r\n",
    "        self.w_vs = nn.Linear(dim_kv, n_head * self.d_v, bias=False) # v\r\n",
    "        self.w_vs.weight.data.normal_(std=1.0 / np.sqrt(dim_kv))\r\n",
    "\r\n",
    "        self.fc = nn.Linear(n_head * self.d_v, dim_q, bias=True) # c\r\n",
    "        self.fc.weight.data.normal_(std=1.0 / np.sqrt(dim_q * n_layer))\r\n",
    "\r\n",
    "        self.attn = SparseAttention(shape, n_head, causal, **attn_kwargs)\r\n",
    "\r\n",
    "    def forward(self, q, k, v):\r\n",
    "        # compute k, q, v\r\n",
    "        d_k, d_v, n_head = self.d_k, self.d_v, self.n_head\r\n",
    "        q = view_range(self.w_qs(q), -1, None, (n_head, d_k))\r\n",
    "        k = view_range(self.w_ks(k), -1, None, (n_head, d_k))\r\n",
    "        v = view_range(self.w_vs(v), -1, None, (n_head, d_v))\r\n",
    "\r\n",
    "        # b x n_head x seq_len x d\r\n",
    "        # (b, *d_shape, n_head, d) -> (b, n_head, *d_shape, d)\r\n",
    "        q = shift_dim(q, -2, 1)\r\n",
    "        k = shift_dim(k, -2, 1)\r\n",
    "        v = shift_dim(v, -2, 1)\r\n",
    "        \r\n",
    "        a = self.attn(q, k, v, decode_step, decode_idx)\r\n",
    "\r\n",
    "        # (b, *d_shape, n_head, d) -> (b, *d_shape, n_head * d)\r\n",
    "        a = shift_dim(a, 1, -2).flatten(start_dim=-2)\r\n",
    "        a = self.fc(a) # (b x seq_len x embd_dim)\r\n",
    "\r\n",
    "        return a"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class SpaTemSelfAtteBlock(nn.Module):\r\n",
    "    \"\"\"Define the Multi-head attention -> Add&Norm -> Feed Forward -> Add&Norm module\"\"\"\r\n",
    "    def __init__(self, shape, embd_dim, n_head, n_layer, dropout=0.2,\r\n",
    "                 attn_type, attn_dropout, class_cond_dim, frame_cond_shape):\r\n",
    "        super.__init__()\r\n",
    "\r\n",
    "        self.shape = shape\r\n",
    "        # Multi-head attention sub-layer\r\n",
    "        self.mh_attn = MultiHeadAttention(shape, embd_dim, embd_dim, n_head, n_layer)\r\n",
    "        self.norm_1 = nn.LayerNorm(embd_dim, class_cond_dim)\r\n",
    "        \r\n",
    "        # Feed forward sub-layer\r\n",
    "        self.fc = nn.Sequential(\r\n",
    "            nn.Linear(in_features=embd_dim, out_features=embd_dim*4),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Dropout(dropout)\r\n",
    "            nn.Linear(in_features=embd_dim*4, out_features=embd_dim)\r\n",
    "        )\r\n",
    "        self.norm_2 =  nn.LayerNorm(embd_dim, class_cond_dim)\r\n",
    "    \r\n",
    "    def forward(self, x, cond, decode):5\r\n",
    "        y1 = self.mh_attn(x)\r\n",
    "        y2 = self.norm_1(x+y1)\r\n",
    "        y3 = self.fc(y2)\r\n",
    "        out = self.norm_2(y2+y3)\r\n",
    "        return out\r\n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class EncoderLayer(nn.Module):\r\n",
    "    \"\"\"Use a CNN to extract information from each frame\"\"\"\r\n",
    "    def __init__(self, c_in, n_classes, use_gt=True, embd_dim, dropout):\r\n",
    "        super(MyTransSeg, self).__init__():\r\n",
    "            self.backbone = CNNBackbone()\r\n",
    "            self.pos_en = PositionEmbeddingSine(embd_dim, dropout)\r\n",
    "            self.encoder = "
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('datasci': conda)"
  },
  "interpreter": {
   "hash": "23d8489b17aa989cee42bd3f3e82cc035b4cfa42fa1ea343caf5051171f57614"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}